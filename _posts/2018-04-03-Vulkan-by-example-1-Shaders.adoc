= Vulkan by example 1 - Shaders
:hp-tags: c++, vulkan, glsl

In the https://TODO[previous lesson] we made all necessary preparations to start exploring vulkan. Here is the diagramm of the current state of the application:

[picture]

The diagramm is pretty empty now but it will grow as we progress through tutorials. For now it's enough to know that there's a CPU, which controls the application and sends commands to the GPU; a GPU itself, which do magic and produces nice pictures (not necessarily); a window which should these pictures to show. The window put in a separate category because the presentation of the picture controlled by an OS and not by an application or a GPU.

The main question for now - where to start? There are so many things to do, there are so many ways to do it. We start from the heart of every graphics application - shaders. After all this is exactly what GPU runs and we're here to programm the GPU. In the app we will use 4 shader stages - Vertex, Tesselation Control, Tesselation Evaluation, Fragment. Let's step over all of these stages briefly explaining the purpose of each.

===== Vertex shader

https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/resources/VertexShader.vert[Vertex shader] is the first stage in the pipeline and it's pretty simple. Looking back to the teapot data I know what information needs to be passed - since I'm using patches I need to provide points describing them - `16` points for every patch.

A patch point arrives to the shader at *location 0* and simply passed through to the next stage. This stage will be executed for every point (vertex) provided. Since I use `28` patches `16` point each it will be called at least `28 * 16 = 448` times (it's not an important information - just for fun).

===== Tessellation control shader

The next shader - https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/resources/TesselationControlShader.tesc[tesselation control shader] -  is simple as well since it doesn't do a lot of work. But still it have a couple of interesting things. The first one is how the tesselation level (how many new triangles a tesselator should create) is updated. I decided to use the so called `Push Constant` - a feature that allows to pass a constant directly in a command buffer, for now read it as fast and simple way and later I'll explain what this means when we'll reach the actual code. As you can see the tesselation level is a float variable and it is somehow updated from the CPU.

Next we tell the GPU that this stage produces 16 control points for the patch, i.e. we doesn't change the amount (yes, this stage can generate new points as well as remove some). And the number of executions of this shader is equal to the number specified out poinst times number of patches, i.e. `28 * 16 = 448` in our case.

===== Tessellation Evaluation shader

The https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/resources/TesselationEvaluationShader.tese[tessellation evaluation shader] is the actual workhorse of the whole application - all the magic happens here.

First we specify tesselation rules: domain (`quad`), spacing (`fractional_odd_spacing`) and winding order (`cw` - clockwise). Next we define the patch information in the form of a buffer. Again, no information right now - just know that each patch should be transformed and colored (see previous lesson for more details why) and the information incoming as an array of `PatchData` at a *binding slot 0*. Also I need transformation matrices. I could provide one MVP-matrix and reduce the number of calculations but I want to show how to deal with multiple uniform buffers in `Vulkan`. That's why there are three matrices: model, view and projection. And they are *binded to slots 1, 2, and 3*.

Next is a scary math - calculation of a 3d point using a `gl_TessCoord` that came from the tesselator. Actually the math is not that complicated, I found https://www.gamasutra.com/view/feature/131755/curved_surfaces_using_bzier_.php[this gamasutra article] very good at explaining the theory behind curves. And the code itself (functions `bernsteinBasis()` and `evaluateBezier()`) I shamelesly took from http://www.gdcvault.com/play/1012740/direct3d[this gdc presentation].

The outputs of this shader are newly generated vertex position and color. Since the entire patch colored with a solid color every vertex from the same patch will have the same attribute.

I think it's obvious that a number of executions of this shader is equal to a number vertices produced by the tesselator. So it depends on the tesselation factor, provided in a tesselation control shader.

===== Fragment shader

----
#version 450

layout(location = 0) out vec4 outColor;

layout(location = 0) in vec3 fragColor;

void main()
{
    outColor = vec4(fragColor, 1.0);
}
----

Another one _"lazy"_ shader - the data is coming at input location `0` and going to the output location `0`. The last one tells that there should be some special memory region (`Image` in that case) somewhere to keep the color.

Hurray! The application is almost done! Joking. Once I read the sentense which describes `Vulkan` in a nutshell: _"Show me your triangle in three months."_ So be patient. I'm planning to write `7` or `8` parts in total. Shaders were the easiest part, and all the remaining code we need to write should serve a single purpose - to make the shaders run. And run *correctly*. By correctness I mean that there should not be undefined behavior, data races, pipeline stalls.

===== Finally some Vulkan

So I have some shaders written as text which I can't use directly. In `Vulkan` shaders have to be compiled to so called `SPIR-V` binary format and supplied to the API via `VkShaderModule`. I can create one with `vkCreateShaderModule` function. Here's the definition of this function:

----
VkResult vkCreateShaderModule(
    VkDevice                                    device,
    const VkShaderModuleCreateInfo*             pCreateInfo,
    const VkAllocationCallbacks*                pAllocator,
    VkShaderModule*                             pShaderModule);
----

Last parameter (`pShaderModule`) is a return value I'm interesting in. Third parameter (`pAllocator`) used for custom allocation and *never* will be used in these lessons (always `nullptr`). Second parameter (`pCreateInfo`) is an information which describes a shader. But the first parameter (`device`) is an unknown variable.

`VkDevice` is a software representation of `GPU`. I think about it like an instance of a real physical `GPU` - it is possible to have multiple instances of it (though we will use only one). I can create a device with `vkCreateDevice` function:

----
VkResult vkCreateDevice(
    VkPhysicalDevice                            physicalDevice,
    const VkDeviceCreateInfo*                   pCreateInfo,
    const VkAllocationCallbacks*                pAllocator,
    VkDevice*                                   pDevice);
----

`pDevice` - return value, `pAllocator` - `nullptr`, `pCreateInfo` - some information, `physicalDevice` - again unknown.

Continuing our OOP the analogy `VkPhysicalDevice` is a class itself or a blueprint. It represents unique piece of hardware and can be used for obtaining some useful info, like capabilities of the `GPU`. It exist as a single instance and we can't create it, but can ask the API to give it to us with `vkEnumeratePhysicalDevices` call - this function enumerates available physical devices in a system:

----
VkResult vkEnumeratePhysicalDevices(
    VkInstance                                  instance,
    uint32_t*                                   pPhysicalDeviceCount,
    VkPhysicalDevice*                           pPhysicalDevices);
----

It will never end... Here again we see an unknown variable `instance`. Moreover, this function can return a list of *all* available devices in the system but I'm interested only in one. For the application I need a GPU that supports tesselation and can output images to the operating system's presentation engine. Yes, it sounds weird but it looks like there are devices that can't render, at least in theory. In order to check device's _"presentability"_ I need some information about render surface. In `Vulkan` this information stored in `VkSurfaceKHR` object and I need to get this object. Fortunately with `GLFW` library this is an easy task:

----
VkResult glfwCreateWindowSurface(
    VkInstance instance,
    GLFWwindow * window,
    const VkAllocationCallbacks * allocator,
    VkSurfaceKHR * surface 
)
----

Again `VkInstance`. It is an entity that keeps the state of the application and which we can create with `vkCreateInstance` function:

----
VkResult vkCreateInstance(
    const VkInstanceCreateInfo*                 pCreateInfo,
    const VkAllocationCallbacks*                pAllocator,
    VkInstance*                                 pInstance);
----

Previously I wrote that `GLFW` library helps with creation of a surface. But this surface thing is special. `VkSurfaceKHR` - this `KHR` ending means that this object is not a part of a _standard_ vulkan, but object which can be obtained through *extensions*. Indeed, presentation is so OS specific that it's very hard to make it as a part of a standard. Or there could be some vendor specific extensions that adds some new functionality. There are instance-level extensions and device-level extensions. Extensions are just strings and I specify them like this in the application:

----
_appData.instanceExtensions.push_back(VK_EXT_DEBUG_REPORT_EXTENSION_NAME);
_appData.deviceExtensions.push_back(VK_KHR_SWAPCHAIN_EXTENSION_NAME);
----

Finally no more unknown variables! But I already forgot why do I need all this... Ah, I wanted to create `Shader Modules`.

To summarize: here's the dependency chain:

----
VkShaderModule 游목 VkDevice 游목 VkPhysicalDevice 游목 VkSurfaceKHR 游목 VkInstance 游목 extensions
----

And here's how this chain is managed in the code:

----
// MainApplication.cpp
MainApplication::MainApplication(uint32_t const windowWidth, uint32_t const windowHeight, std::string const & appName) : MainApplication{}
{
	app::MaybeWindow const mbWindow{app::create_window(windowWidth, windowHeight, appName)};
	
	if (!mbWindow)
		throw std::runtime_error{mbWindow.error()};
	
	m_appData.window = *mbWindow;
	
	glfwSetWindowUserPointer(m_appData.window, &m_appData);
	glfwSetKeyCallback(m_appData.window, &app::on_key_press);
	glfwSetWindowSizeLimits(m_appData.window, 640, 480, GLFW_DONT_CARE, GLFW_DONT_CARE);
	glfwSetFramebufferSizeCallback(m_appData.window, app::framebuffer_size_callback);

	app::MaybeAppData mbData{app::MaybeAppData{app::get_required_window_extensions(std::move(m_appData))} // #1
	                         .and_then(app::create_instance) // #2
	                         .and_then(app::create_surface) // #3
	                         .and_then(app::get_physical_device) // #4
	                         .map(app::prepare_device_features) // #5
	                         .and_then(app::create_logical_device) // #6
	                         .and_then(app::create_shader_modules)}; // #7

	if (!mbData)
		throw std::runtime_error{mbData.error()};

	m_appData = std::move(*mbData);

	glfwSetWindowUserPointer(m_appData.window, &m_appData);
}
----

. [[anchor-getting-required-extensions-back]] <<anchor-getting-required-extensions, Getting required extensions>>
. [[anchor-creating-an-instance-back]] <<anchor-creating-an-instance, Creating an instance>>
. [[anchor-creating-a-surface-back]] <<anchor-creating-a-surface, Creating a surface>>
. [[anchor-getting-a-physical-device-back]] <<anchor-getting-a-physical-device, Getting a physical device>>
. [[anchor-preparing-physical-device-features-back]] <<anchor-preparing-physical-device-features, Preparing physical device features>>
. [[anchor-creating-a-logical-device-back]] <<anchor-creating-a-logical-device, Creating a logical device>>
. [[anchor-creating-shader-modules-back]] <<anchor-creating-shader-modules, Creating shader modules>>

Here `MaybeAppData` is an alias to `tl::expected` (a library as a replacement for non-existent yet `std::expected`, see the https://TODO[previous article]) - it can hold an an `AppData` object or be empty, hence the suffix `maybe`.

----
using MaybeAppData = tl::expected<AppData, std::string>;
----

Just look how beautiful the code is. If the first call fails all other calls will not be executed and `expected` object will hold an error instead of valid value. By this error I can find the fail reason. Each function in the chain is a standalone pure function in separate unit - that's how I'm trying to fight the verbosity of a `Vulkan` application (the number of lines easily gets over 1000 even in a simple triangle application). Now I'm going to visit each function trying to explain what it does.

[[anchor-getting-required-extensions]]
===== Getting required extensions

This one is simple because `GLFW` library helps:

----
AppData get_required_window_extensions(AppData data)
{
	uint32_t glfwExtensionCount{0};
	char const * const * const glfwExtensions{glfwGetRequiredInstanceExtensions(&glfwExtensionCount)};
		
	for (uint32_t i{0}; i < glfwExtensionCount; ++i)
		data.instanceExtensions.push_back(glfwExtensions[i]);
		
	return data;
}
----

http://www.glfw.org/docs/latest/group__vulkan.html#ga1abcbe61033958f22f63ef82008874b1[`glfwGetRequiredInstanceExtensions`] returns a list of extesion names required for surface creation. I need this list to create a `VkInstance`, i.e. I need to be sure that my system can draw anything on the screen.

NOTE: I could pass a const reference to `AppData` to avoid copying, but since I need a copy anyway to return a new the state (remember - all functions should be pure) I just let the runtime to do one.

<<anchor-getting-required-extensions-back, Back>>

[[anchor-creating-an-instance]]
===== Creating an instance

With instance extensions names I can create an instance.

----
MaybeAppData create_instance(AppData data)
{
	helpers::MaybeInstance const mbInstance{helpers::create_instance(&data.instanceExtensions, &data.layers)};
	if(!mbInstance)
		return tl::make_unexpected(mbInstance.error());
	
	data.instance = *mbInstance;
	
	return data;
}
----

where `helpers::create_instance` declared/defined in `VkObjectHelpers.h/cpp` files:

----
// VkObjectHelpers.h
using MaybeInstance = tl::expected<VkInstance, std::string>;

// VkObjectHelpers.cpp
MaybeInstance create_instance(vector<char const *> const * const extensions, std::vector<char const *> const * const layers, VkApplicationInfo const * const applicationInfo)
{
	VkInstanceCreateInfo const createInfo{get_instance_create_info(extensions, layers, applicationInfo)};
	
	VkInstance instance{VK_NULL_HANDLE};
	if (vkCreateInstance(&createInfo, nullptr, &instance) != VK_SUCCESS)
	return make_unexpected("failed to create instance");
	
	return instance;
}
----

All objects in `Vulkan` are created by providing information through corrsponding structures. For an instance this structure is `VkInstanceCreateInfo`. I isolated all structure creations in `VkStructHelpers.h/cpp` files.

NOTE: It's possible to use https://github.com/KhronosGroup/Vulkan-Hpp[Vulkan-Hpp] `c++` wrapper by `Khronos`, but I decided to go low-level in this lessons by multiple reasons - first I want to understand every bit of code and for this I want to type everything by myself, and the second reason is a `vulkan.hpp`'s size - it's almost 2MB and more than 40000 lines of code! Man, I don't want to retire waiting the compilation is done.

----
VkInstanceCreateInfo get_instance_create_info(vector<char const *> const * const extensions, vector<char const *> const * const layers, VkApplicationInfo const * const applicationInfo)
{
	VkInstanceCreateInfo info{};
	info.sType = VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO; // #1
	info.pNext = nullptr; // #2
	info.flags = 0; // #3
	info.pApplicationInfo = applicationInfo; // #4
	info.enabledLayerCount = (layers) ? static_cast<uint32_t>(layers->size()) : 0; // #5
	info.ppEnabledLayerNames = (layers) ? layers->data() : nullptr;
	info.enabledExtensionCount = (extensions) ? static_cast<uint32_t>(extensions->size()) : 0; // #6
	info.ppEnabledExtensionNames = (extensions) ? extensions->data() : nullptr;
	
	return info;
}
----

. Every structure in `Vulkan` have a corresponding name. For `VkInstanceCreateInfo` it is `VK_STRUCTURE_TYPE_INSTANCE_CREATE_INFO`, for other types - other names. I will not mention this anymore for new structures.

. Some information objects can be extended by providing another structure in `pNext` member. For example, information for device memory creation can be extended with additional data that marks memory as shared. This application will not use that feature so I will not mention it anymore.

. This structure doesn't use any flags. In future I will only describe `flags` field only if it's not empty.

. This structure can provide information about application to the driver with `VkApplicationInfo` struct. Since it's only informatical I pass a `nullptr`.

. Layers are used for debugging. In this lesson it's too early for debugging and `layers` vector is empty. Notice how arrays are passed to `Vulkan` - there's no `std::vector` or other similar data structures - only raw pointers. And every array accompanied with it's size.

. I provide extensions I got from `GLFW` window.

<<anchor-creating-an-instance-back, Back>>

[[anchor-creating-a-surface]]
===== Creating a surface

----
MaybeAppData create_surface(AppData data)
{
	assert(data.instance);
	assert(data.window);
	
	if (glfwCreateWindowSurface(data.instance, data.window, nullptr, &data.surface) != VK_SUCCESS)
		return tl::make_unexpected("failed to create window surface");
	
	return data;
}
----

Again `GLFW` library takes care of surface creation with http://www.glfw.org/docs/latest/group__vulkan.html#ga1a24536bec3f80b08ead18e28e6ae965[`glfwCreateWindowSurface`] function which returns `VkResult` indicating the result of the call. Under the hood the library calls platform specific `Vulkan` function, like `vkCreateWin32SurfaceKHR` for `Windows` which uses corresponding info structure `VkWin32SurfaceCreateInfoKHR`. But `GLFW` hides this platform dependent call and this is why I use it.

<<anchor-creating-a-surface-back, Back>>

[[anchor-getting-a-physical-device]]
===== Getting a physical device

We have the Vulkan instance and the window surface, now we can enumerate all available devices (GPUs) and select one fulfilling our needs.

----
MaybeAppData get_physical_device(AppData data)
{
	assert(data.instance);
	assert(data.surface);
	
	helpers::MaybePhysicalDevices const mbPhysicalDevices{helpers::get_physical_devices(data.instance)}; // #1
	if(!mbPhysicalDevices)
		return tl::make_unexpected(mbPhysicalDevices.error());
	
	vector<VkPhysicalDevice> const & physicalDevices{*mbPhysicalDevices};
	
	for(VkPhysicalDevice const d : physicalDevices)
	{
		if(!check_device_suitability(d, data.deviceExtensions)) // #2
			continue;
		
		MaybeSurfaceFormat const mbSurfaceFormat{get_device_surface_format(d, data.surface)}; // #3
		if(!mbSurfaceFormat)
			continue;
		
		MaybePresentMode const mbPresentMode{get_device_surface_present_mode(d, data.surface)}; // #4
		if(!mbPresentMode)
			continue;
		
		MaybeQueueFamilies const mbQueueFamilies{get_device_graphics_and_present_queue_families(d, data.surface)}; // #5
		if(!mbQueueFamilies)
			continue;
		
		data.physicalDevice = d;
		tie(data.graphicsFamilyQueueIndex, data.presentFamilyQueueIndex) = *mbQueueFamilies;
		data.surfaceFormat = *mbSurfaceFormat;
		data.surfacePresentMode = *mbPresentMode;
		
		vkGetPhysicalDeviceProperties(data.physicalDevice, &data.physicalDeviceProperties); // #6
		
		return data;
	}
	
	return tl::make_unexpected("failed to find suitable device");
}
----

As can be seen the function calls other functions. Let's investigate each in order.

. [[anchor-getting-physical-devices-back]] <<anchor-getting-physical-devices, Getting physical devices>>
. [[anchor-checking-physical-device-suitability-back]] <<anchor-checking-physical-device-suitability, Checking physical device suitability>>
. [[anchor-getting-physical-device-surface-format-back]] <<anchor-getting-physical-device-surface-format, Getting physical device surface format>>
. [[anchor-getting-physical-device-surface-present-mode-back]] <<anchor-getting-physical-device-surface-present-mode, Getting physical device surface present mode>>
. [[anchor-getting-queues-families-back]] <<anchor-getting-queues-families, Getting queues families>>
. [[anchor-getting-physical-device-properties-back]] <<anchor-getting-physical-device-properties, Getting physical device properties>>

[[anchor-getting-physical-devices]]
*Getting a physical device*

First I get all available devices in my system with the helper function:

----
MaybePhysicalDevices get_physical_devices(VkInstance const instance)
{
	assert(instance);
	
	uint32_t deviceCount{0};
	if(vkEnumeratePhysicalDevices(instance, &deviceCount, nullptr) != VK_SUCCESS || deviceCount == 0) // #a
		return make_unexpected("failed to find GPUs with Vulkan support");
	
	vector<VkPhysicalDevice> physicalDevices(deviceCount);
	if(vkEnumeratePhysicalDevices(instance, &deviceCount, physicalDevices.data()) != VK_SUCCESS) // #b
		return make_unexpected("failed to find GPUs with Vulkan support");
	
	return physicalDevices;
}
----

.. A typical pattern in `Vulkan` - if you want to get the number of something you call a function with a null argument. So I call `vkEnumeratePhysicalDevices` with last argument as `nullptr` and the implementation fills `deviceCount` with an actual number of devices.

.. This time I call `vkEnumeratePhysicalDevices` with a pointer to the container and the implementation fills the container with `deviceCount` physical devices.

<<anchor-getting-physical-devices-back, Back>>

[[anchor-checking-physical-device-suitability]]
*Checking physical device suitability*

Next I iterate over all devices and check if the current one fits our needs:

----
bool check_device_suitability(VkPhysicalDevice const physicalDevice, vector<char const *> const & requiredExtensions)
{
	VkPhysicalDeviceProperties deviceProperties{};
	vkGetPhysicalDeviceProperties(physicalDevice, &deviceProperties); // #a
	
	if (deviceProperties.deviceType != VK_PHYSICAL_DEVICE_TYPE_DISCRETE_GPU) // #b
		return false;
	
	VkPhysicalDeviceFeatures deviceFeatures{};
	vkGetPhysicalDeviceFeatures(physicalDevice, &deviceFeatures); // #c
	
	if (!deviceFeatures.tessellationShader) // #d
		return false;
	
	if (deviceProperties.limits.maxTessellationPatchSize < 16) // #e
		return false;
	
	if (!deviceFeatures.fillModeNonSolid) // #f
		return false;
	
	if (!check_required_device_extensions(physicalDevice, requiredExtensions)) // #g
		return false;
	
	return true;
}
----

.. First I get device properties with `vkGetPhysicalDeviceProperties` call. This function never fails according to specs so no checks here.

.. One of my test machines have 2 GPUs and I want to use the more powerfull one so I ignore all non discrete adapters (i.e. integrated). But if your laptop have a modern Intel GPU you can remove this check.

.. Next I get device features. The difference between properties and features is that the former is a general properties which just show the GPU capabilities while the latter can be enabled or disabled per request.

.. Here I check that a _tesselation feature_ can be enabled for the considered device.

.. Next I check the size of a patch. Remember that I'm using 16 point patches so I need to be sure the GPU knows how to deal with them. This is a GPU _property_ and it can be requested only if the corresponding _feature_ (`deviceFeatures.tessellationShader`) is supported.

.. Next feature to check is an ability to draw in wireframe mode.

.. And the last one thing to do for now is to check if required extensions are supported by the selected device. Remember, earlier I mentioned extensions and we even added some for the instance creation. You can think of instance extensions as global ones, i.e. you turn them on once per application. But device extensions can be turned on, well, per device. One of the examples of such extensions is `VK_KHR_SWAPCHAIN_EXTENSION_NAME` - the extension that is needed for swap chain creation. Since we don't know yet what is it this list of required extensions is empty. But later when we need one we just add the string to the vector. The `check_required_device_extensions` defined so:

----
bool check_required_device_extensions(VkPhysicalDevice const physicalDevice, vector<char const *> const & requiredExtensions)
{
	app::helpers::MaybeExtensionProperties mbExtensions{app::helpers::get_physical_device_device_extension_properties(physicalDevice)};
	if(!mbExtensions)
		return false;
	
	vector<VkExtensionProperties> const & availableExtensions{*mbExtensions};
	
	for (char const * element : requiredExtensions)
	{
		if (find_if(begin(availableExtensions), end(availableExtensions), [element](VkExtensionProperties const & extensionProp) { return strcmp(element, extensionProp.extensionName) == 0; }) == end(availableExtensions))
			return false;
	}
	
	return true;
}
----

Where the helper function lools like this:

----
MaybeExtensionProperties get_physical_device_device_extension_properties(VkPhysicalDevice const physicalDevice)
{
	assert(physicalDevice);
	
	uint32_t extensionCount{0};
	if (vkEnumerateDeviceExtensionProperties(physicalDevice, nullptr, &extensionCount, nullptr) != VK_SUCCESS)
		return make_unexpected("failed to get physical device extension properties");
	
	vector<VkExtensionProperties> extensions(extensionCount);
	if (vkEnumerateDeviceExtensionProperties(physicalDevice, nullptr, &extensionCount, extensions.data()) != VK_SUCCESS)
		return make_unexpected("failed to get physical device extension properties");
	
	return extensions;
}
----

Here we see the familiar pattern for obtaining the list of elements of unknown size in Vulkan.

<<anchor-checking-physical-device-suitability-back, Back>>

[[anchor-getting-physical-device-surface-format]]
*Getting physical device surface format*

Next I try to get an underlying window surface format - we need to know it since we want to render to that surface and we want our picture to be correct.

----
MaybeSurfaceFormat get_device_surface_format(VkPhysicalDevice const physicalDevice, VkSurfaceKHR const surface)
{
	app::helpers::MaybePhysicalDevicesSurfaceFormats const mbFormats{app::helpers::get_physical_devices_surface_formats(physicalDevice, surface)}; // #a
	if (!mbFormats)
		return tl::make_unexpected(mbFormats.error());
	
	vector<VkSurfaceFormatKHR> const formats{*mbFormats};

	if (formats.size() == 1 && formats[0].format == VK_FORMAT_UNDEFINED)
		return VkSurfaceFormatKHR{VK_FORMAT_B8G8R8A8_UNORM, VK_COLOR_SPACE_SRGB_NONLINEAR_KHR}; // #b
	
	if (auto const it = find_if(begin(formats), end(formats), [](VkSurfaceFormatKHR const f) { return f.format == VK_FORMAT_B8G8R8A8_UNORM && f.colorSpace == VK_COLOR_SPACE_SRGB_NONLINEAR_KHR; }); it != end(formats))
		return VkSurfaceFormatKHR{VK_FORMAT_B8G8R8A8_UNORM, VK_COLOR_SPACE_SRGB_NONLINEAR_KHR}; // #c
	
	return formats[0]; // #d
}
----

.. `get_physical_devices_surface_formats` lives in the helper file:

----
MaybePhysicalDevicesSurfaceFormats get_physical_devices_surface_formats(VkPhysicalDevice const physicalDevice, VkSurfaceKHR const surface)
{
	assert(physicalDevice);
	assert(surface);
	
	uint32_t formatsCount{0};
	if (vkGetPhysicalDeviceSurfaceFormatsKHR(physicalDevice, surface, &formatsCount, nullptr) != VK_SUCCESS)
		return make_unexpected("failed to get physical device surface formats");
	
	vector<VkSurfaceFormatKHR> formats(formatsCount);
	if (formatsCount == 0 || vkGetPhysicalDeviceSurfaceFormatsKHR(physicalDevice, surface, &formatsCount, formats.data()) != VK_SUCCESS)
		return make_unexpected("failed to get physical device surface formats");
	
	return formats;
}
----

Nothing new or anything to talk about. It just gives us the list of all formats gpu supports for the given device and the surface.

[start=2]
.. Having a list of supported formats for the selected device we need to choose the one we will use. Here's a quote from the specification:

[source]
----
If pSurfaceFormats includes just one entry, whose value for format is VK_FORMAT_UNDEFINED, surface has no preferred format. In this case, the application can use any valid VkFormat value.
----

So if this condition is true I simply return `VK_FORMAT_B8G8R8A8_UNORM` as format and `VK_COLOR_SPACE_SRGB_NONLINEAR_KHR` as a color space.

[start=3]
.. If the previous condition was not true I iterate over all supported formats searching for the one I like (`{VK_FORMAT_B8G8R8A8_UNORM, VK_COLOR_SPACE_SRGB_NONLINEAR_KHR}`).

.. Finally if the desired format was not found I just return the first one.

<<anchor-getting-physical-device-surface-format-back, Back>>

[[anchor-getting-physical-device-surface-present-mode]]
*Getting physical device surface present mode*

Next I try to get an underlying window surface pesent mode. As you now a monitor works with some fequency. For example, if the monitor have the frequency 60Hz it needs to present a picture every 1/60th of a second. The OS takes care about this presentation and all we need to do is to provide presentation engine an image to show. Also you may know that a monitors displays a picture not immidiately but line by line, it just do it very fast. Now think what can happen if,say the engine displayed a half of the picture and we provided a new one? Right - the engine continues to present but the picture it started with but the new one. So on the screen we have the combination of two images - so called _tearing_. Sometimes this is a desirable behavior and sometimes we want to avoid it. This is why we need to specify a presentation mode. And this is how I do it in code:

----
MaybePresentMode get_device_surface_present_mode(VkPhysicalDevice const physicalDevice, VkSurfaceKHR const surface)
{
	app::helpers::MaybePhysicalDevicesSurfacePresentModes const mbPresentModes{app::helpers::get_physical_device_surface_present_modes(physicalDevice, surface)}; // #a
	if (!mbPresentModes)
		return tl::make_unexpected(mbPresentModes.error());
	
	vector<VkPresentModeKHR> const presentModes{*mbPresentModes};

	if (auto const it = find(begin(presentModes), end(presentModes), VK_PRESENT_MODE_MAILBOX_KHR); it != end(presentModes)) // #b
		return VK_PRESENT_MODE_MAILBOX_KHR;
	
	if (auto const it = find(begin(presentModes), end(presentModes), VK_PRESENT_MODE_IMMEDIATE_KHR); it != end(presentModes)) // #c
		return VK_PRESENT_MODE_IMMEDIATE_KHR;
	
	return VK_PRESENT_MODE_FIFO_KHR; // #d
}
----

.. `get_physical_device_surface_present_modes` is in the helper file:

----
MaybePhysicalDevicesSurfacePresentModes get_physical_device_surface_present_modes(VkPhysicalDevice const physicalDevice, VkSurfaceKHR const surface)
{
	assert(physicalDevice);
	assert(surface);
	
	uint32_t presentModesCount{0};
	if (vkGetPhysicalDeviceSurfacePresentModesKHR(physicalDevice, surface, &presentModesCount, nullptr) != VK_SUCCESS)
		return make_unexpected("failed to get physical device surface present modes");
	
	vector<VkPresentModeKHR> presentModes(presentModesCount);
	if (presentModesCount == 0 || vkGetPhysicalDeviceSurfacePresentModesKHR(physicalDevice, surface, &presentModesCount, presentModes.data()) != VK_SUCCESS)
		return make_unexpected("failed to get physical device surface present modes");
	
	return presentModes;
}
----

Nothing spesial here.

[start=2]
.. If we don't want the tearing in our application we tell presentation engine to use it's internal queue - now the pending requests will be added to that queue and when the engine is ready to display it aquires the image from the queue begining by removing it. So we never see the tearing. `VK_PRESENT_MODE_MAILBOX_KHR` tells engine to use a single-entry queue, meaning that the pending requests will be replaced by newest ones. There's no guarantee that the GPU supports this mode.

.. If the previous attempt to find a mode was not succesfull we try to find another one - `VK_PRESENT_MODE_IMMEDIATE_KHR`. This mode does not use a queue so it behaves like I described above - with a possible tearing. The mode is not guaranteed to be presented.

.. `VK_PRESENT_MODE_FIFO_KHR` is the only mode required to be supported so I return it if previous attempts failed. This mode uses a queue as well but the size is not specified (I suppose it's implementation-defined). The difference with `VK_PRESENT_MODE_MAILBOX_KHR` is  that if the queue is full the application will be blocked until the engine remove available image and free the place in the queue.

<<anchor-getting-physical-device-surface-present-mode-back, Back>>

[[anchor-getting-queues-families]]
*Getting queues families*

In this step I'm trying to get so called _queue families_ for the device. As you may know the CPU communicates with the GPU via commands. In Vulkan we record these commands with special functions like `vkCmdDraw` or `vkCmdBindVertexBuffers` to a so called _command buffer_. After a set of commands is ready it needs to be sent to the device. We don't send it directly but put to some queue and the implementation later consumes that queue. I understand these queues as connections between the CPU and the GPU (software connections of course). Vulkan defines 5 different family queues - `VK_QUEUE_GRAPHICS_BIT`, `VK_QUEUE_COMPUTE_BIT`, `VK_QUEUE_TRANSFER_BIT`, `VK_QUEUE_SPARSE_BINDING_BIT` and `VK_QUEUE_PROTECTED_BIT`. Each queue supports certain operations so we need to be carefull when submiting commands. Specification tells supported queue type for every command. There's one guarantee from Vulkan that graphics queue (`VK_QUEUE_GRAPHICS_BIT`) supports transfer operations as well, so if you have to submit a transfer command you can do it with that queue, no need to create a transfer queue (`VK_QUEUE_TRANSFER_BIT`).

So why do we need multiple queue families? Well, in theory using multiple queues can speed up the application - the submission of commands hapeens in parallel. And you know the word _parralel_ is the sinonym to _good_. How this works is described by Matt Pettineo (aka MJP) in these https://mynameismjp.wordpress.com/2018/03/06/breaking-down-barriers-part-1-whats-a-barrier/[amazing article series].

There's another thing. Each queue family can have *multiple* queues, hence the name _family_. So, again in theory, you can use multiple queues from the same family to submit commands faster, you just need a proper GPU. 

----
MaybeQueueFamilies get_device_graphics_and_present_queue_families(VkPhysicalDevice const physicalDevice, VkSurfaceKHR const surface)
{
	vector<VkQueueFamilyProperties> const queueFamilies{app::helpers::get_queue_family_properties(physicalDevice)}; // #a
	
	for (size_t i{0}; i < queueFamilies.size(); ++i) // #b
	{
		VkQueueFamilyProperties queueFamily{queueFamilies[i]};
		
		if (queueFamily.queueCount > 0 && (queueFamily.queueFlags & VK_QUEUE_GRAPHICS_BIT))
		{
			VkBool32 presentSupported{VK_FALSE};
			vkGetPhysicalDeviceSurfaceSupportKHR(physicalDevice, static_cast<uint32_t>(i), surface, &presentSupported);
			
			if (presentSupported)
				return make_tuple(static_cast<uint32_t>(i), static_cast<uint32_t>(i));
		}
	}
	
	int graphicsQueueIndex{-1};
	for (size_t i{0}; i < queueFamilies.size(); ++i) // #c
	{
		VkQueueFamilyProperties queueFamily{queueFamilies[i]};
		
		if (queueFamily.queueCount > 0 && queueFamily.queueFlags & VK_QUEUE_GRAPHICS_BIT)
		{
			graphicsQueueIndex = static_cast<int>(i);
			break;
		}
	}
	
	if (graphicsQueueIndex == -1)
		return tl::make_unexpected("failed to find graphics queue");
	
	int presentQueueIndex{-1};
	for (size_t i{0}; i < queueFamilies.size(); ++i) // #d
	{
		VkQueueFamilyProperties const queueFamily{queueFamilies[i]};
		
		if (queueFamily.queueCount > 0)
		{
			VkBool32 presentSupported{VK_FALSE};
			vkGetPhysicalDeviceSurfaceSupportKHR(physicalDevice, static_cast<uint32_t>(i), surface, &presentSupported);
			
			if (presentSupported)
			{
				presentQueueIndex = static_cast<int>(i);
				break;
			}
		}
	}
	
	if (presentQueueIndex == -1)
		return tl::make_unexpected("failed to find present queue");
	
	return make_tuple(static_cast<uint32_t>(graphicsQueueIndex), static_cast<uint32_t>(presentQueueIndex)); // #e
}
----

.. First I get all available families for the given device.

----
vector<VkQueueFamilyProperties> get_queue_family_properties(VkPhysicalDevice const physicalDevice)
{
	uint32_t queueFamilyCount{0};
	vkGetPhysicalDeviceQueueFamilyProperties(physicalDevice, &queueFamilyCount, nullptr);

	vector<VkQueueFamilyProperties> queueFamilies(queueFamilyCount);
	vkGetPhysicalDeviceQueueFamilyProperties(physicalDevice, &queueFamilyCount, queueFamilies.data());

	return queueFamilies;
}
----

I bet you already can recognize this pattern with closed eyes. Function `vkGetPhysicalDeviceQueueFamilyProperties` can't fail and I return the result directly.

[start=2]
.. Next I try to find proper family queue. In my application I will use 2 different queus. I need to render, i.e. call graphic commands, so `VK_QUEUE_GRAPHICS_BIT` is needed for sure. I check it with a line `queueFamily.queueFlags & VK_QUEUE_GRAPHICS_BIT`. Also I need to present the final image so I need to be sure that the queue family can do this. Function `vkGetPhysicalDeviceSurfaceSupportKHR` takes a device, a family index and a surface and sets `presentSupported` to `true` if the provided queue supports presentation for the provided device and surface. In this block I try to find a single queue which supports both operations. If it found I return family index - the same for both queue families.

.. If the previous search failed I try to find a queue which can do graphics only. If there's no such queue we are doomed and have to run to the nearest shop to buy a modrn GPU.

.. Here I continue my search - try to find a queue which can do presentation only.

.. If both graphics and present queue family indices were found I return them as a tuple.

<<anchor-getting-queues-families-back, Back>>

[[anchor-getting-physical-device-properties]]
*Getting physical device properties*

If the previous step was successfull we got aphysical device that fits our needs. Now I save the information we gathered to a state object. If there was a fail during one of the requests I continue to search.

<<anchor-getting-physical-device-properties-back, Back>>

That's was a lenghty funtion. Thankfully there are not many such a verbose actions so let's move on.

<<anchor-getting-a-physical-device-back, Back>>

[[anchor-preparing-physical-device-features]]
===== Preparing device features.

Since we have a physical device at this point we can create a logical device `VkDevice` with `vkCreateDevice()`. One of the parameters in this function is `VkPhysicalDeviceFeatures`. We can request these features with `vkGetPhysicalDeviceFeatures` as we did when requested for the device suitability and just pass them as it is. But in this case we will activate all supported features even those we are not interested in. This can lead to performance loss. For example, `robustBufferAccess` is not needed for my application and this is what documantation says:

[source]
----
Some features, such as robustBufferAccess, may incur a run-time performance cost. Application writers should carefully consider the implications of enabling all supported features.
----

So I turn on only what I need - tesselation and wireframe rendering.

----
AppData prepare_device_features(AppData data)
{
	data.physicalDeviceFeatures.tessellationShader = VK_TRUE;
	data.physicalDeviceFeatures.fillModeNonSolid = VK_TRUE;
	data.physicalDeviceFeatures.vertexPipelineStoresAndAtomics = VK_TRUE;
	
	return data;
}
----

NOTE: At the moment of writing the validation layers (this topic not covered yet) reports a false error - `Shader requires vertexPipelineStoresAndAtomics but is not enabled on the device`. Though if you look at the tesselation eveluation shader declaration you will see that I marked one of the buffers as `readonly`. This is indeed a bug and already was reported https://github.com/KhronosGroup/Vulkan-ValidationLayers/issues/73[here].

<<anchor-preparing-physical-device-features-back, Back>>

[[anchor-creating-a-logical-device]]
===== Creating logical device

Now it's time for the logical device. Remember, the logical device is a software representation of the gpu and it's needed almost for every other Vulkan function call.

----
MaybeAppData create_logical_device(AppData data)
{
	assert(data.physicalDevice);
	
	std::vector<uint32_t> queueIndices{data.graphicsFamilyQueueIndex}; // #1
	std::vector<std::vector<float>> queueNumAndPriorities{{1.0f}}; // #2
	
	if(data.graphicsFamilyQueueIndex != data.presentFamilyQueueIndex) // #3
	{
		queueIndices.push_back(data.presentFamilyQueueIndex);
		queueNumAndPriorities.push_back({1.0f});
	}
	
	helpers::MaybeDevice const mbDevice{helpers::create_device(data.physicalDevice, &queueIndices, &queueNumAndPriorities, &data.physicalDeviceFeatures, &data.deviceExtensions)}; // #4
	if(!mbDevice)
		return tl::make_unexpected(mbDevice.error());
	
	data.device = *mbDevice;
	
	return data;
}
----

. When creating a logical device we need to tell the driver which queues will be used with the selected gpu. When we selected a physical device we got a couple of queues we need for the application (graphics and present queues) in the form of indices. When the logical device is created the specified queues will be creatte as well.

. If within the family multiple queues are used we can specify priorities for them. A queue with a higher priority theoretically can get more processing time than a queue with a lower priority. In the demo I will use only one queue per family so I simply leave priorities set to 1. By the way, the valid range is in 0.0 - 1.0 interval.

. As I told before the application uses two queues - graphics (for rendering and copy operations) and present (for presenting). It is absolutely valid that a single queue can handle both types of operations and most likely your GPU have such a queue. But for the safety we need to deal with the situation when they are different. So if they are I just provide the index and priority.

. Now I pass the parameters to a helper function:

----
MaybeDevice create_device(VkPhysicalDevice const physicalDevice, vector<uint32_t> const * const queueIndices, vector<vector<float>> const * const queuePriorities, VkPhysicalDeviceFeatures const * const features, vector<char const *> const * const extensions)
{
	assert(physicalDevice);
	assert(queueIndices);
	assert(!queueIndices->empty());
	assert(queuePriorities);
	assert(queueIndices->size() == queuePriorities->size());
	
	vector<VkDeviceQueueCreateInfo> queueCreateInfos{}; // #a
	queueCreateInfos.reserve(queueIndices->size());
	
	for(size_t i{0}; i < queueIndices->size(); ++i)
		queueCreateInfos.push_back(get_device_queue_create_info(queueIndices->at(i), &queuePriorities->at(i))); // #b
	
	VkDeviceCreateInfo const createInfo{get_device_create_info(&queueCreateInfos, features, extensions)}; // #c
	
	VkDevice device{VK_NULL_HANDLE};
	if (vkCreateDevice(physicalDevice, &createInfo, nullptr, &device) != VK_SUCCESS) // #d
		return make_unexpected("failed to create logical device");
	
	return device;
}
----

.. First I reserve a place for `VkDeviceQueueCreateInfo`. I will repeat that in the application the maximum number of queues can be 2 (for graphics and present queue) but usually it will be 1 since most hardware provide a queue that supports both types of operations.

.. Next I create an info for every queue that should be created:

----
VkDeviceQueueCreateInfo get_device_queue_create_info(uint32_t const queueFamilyIndex, vector<float> const * const queuePriorities)
{
	assert(queuePriorities);
	assert(!queuePriorities->empty());
	
	VkDeviceQueueCreateInfo info{};
	info.sType = VK_STRUCTURE_TYPE_DEVICE_QUEUE_CREATE_INFO;
	info.pNext = nullptr;
	info.flags = 0;
	info.queueFamilyIndex = queueFamilyIndex;
	info.queueCount = static_cast<uint32_t>(queuePriorities->size());
	info.pQueuePriorities = queuePriorities->data();
	
	return info;
}
----

[start=3]
.. Next is a logical device info:

----
VkDeviceCreateInfo get_device_create_info(vector<VkDeviceQueueCreateInfo> const * const queueCreateInfos, VkPhysicalDeviceFeatures const * const deviceFeatures, vector<char const *> const * const deviceExtensions)
{
	assert(queueCreateInfos);
	assert(!queueCreateInfos->empty());
	
	VkDeviceCreateInfo info{};
	info.sType = VK_STRUCTURE_TYPE_DEVICE_CREATE_INFO;
	info.pNext = nullptr;
	info.flags = 0;
	info.queueCreateInfoCount = static_cast<uint32_t>(queueCreateInfos->size());
	info.pQueueCreateInfos = queueCreateInfos->data();
	info.enabledLayerCount = 0;
	info.ppEnabledLayerNames = nullptr;
	info.enabledExtensionCount = deviceExtensions ? static_cast<uint32_t>(deviceExtensions->size()) : 0;
	info.ppEnabledExtensionNames = deviceExtensions ? deviceExtensions->data() : nullptr;
	info.pEnabledFeatures = deviceFeatures;
	
	return info;
}
----

At this point you should know every parameter meaning so I will not stop to describe them. Just mention that for now there's no any device extensions.

[start=4]
.. And finaly a Vulkan call. `vkCreateDevice` takes a physical device which logical representation we need and filled info structure and outputs created `VkDevice`.

Haleluja! Now we have everything for our shaders.

<<anchor-creating-a-logical-device-back, Back>>

[[anchor-creating-shader-modules]]
===== Creating shader modules

And again, shader modules creation is done in a standalone function:

----
MaybeAppData create_shader_modules(AppData data)
{
	assert(data.device);
	
	{
		MaybeShaderData const mbShaderData{load_shader("VertexShader.spv")}; // #1
		if (!mbShaderData)
			tl::make_unexpected(mbShaderData.error());

		helpers::MaybeShaderModule const mbVertexShaderModule{helpers::create_shader_module(data.device, &(*mbShaderData))}; // #2
		if (!mbVertexShaderModule)
			return tl::make_unexpected(mbVertexShaderModule.error());

		data.vertexShaderModule = *mbVertexShaderModule;
	}

	{
		MaybeShaderData const mbShaderData{load_shader("TesselationControlShader.spv")};
		if (!mbShaderData)
			tl::make_unexpected(mbShaderData.error());

		helpers::MaybeShaderModule const mbTessControlShaderModule{helpers::create_shader_module(data.device, &(*mbShaderData))};
		if (!mbTessControlShaderModule)
			return tl::make_unexpected(mbTessControlShaderModule.error());

		data.tessControlShaderModule = *mbTessControlShaderModule;
	}

	{
		MaybeShaderData const mbShaderData{load_shader("TesselationEvaluationShader.spv")};
		if (!mbShaderData)
			tl::make_unexpected(mbShaderData.error());

		helpers::MaybeShaderModule const mbTessEvaluationShaderModule{helpers::create_shader_module(data.device, &(*mbShaderData))};
		if (!mbTessEvaluationShaderModule)
			return tl::make_unexpected(mbTessEvaluationShaderModule.error());

		data.tessEvaluationShaderModule = *mbTessEvaluationShaderModule;
	}

	{
		MaybeShaderData const mbShaderData{load_shader("FragmentShader.spv")};
		if (!mbShaderData)
			tl::make_unexpected(mbShaderData.error());

		helpers::MaybeShaderModule const mbFragmentShaderModule{helpers::create_shader_module(data.device, &(*mbShaderData))};
		if (!mbFragmentShaderModule)
			return tl::make_unexpected(mbFragmentShaderModule.error());

		data.fragmentShaderModule = *mbFragmentShaderModule;
	}

	return data;
}
----

. [[anchor-loading-a-shader-binary-back]] <<anchor-loading-a-shader-binary, Loading a shader binary>>
. [[anchor-creating-a-shader-module-back]] <<anchor-creating-a-shader-module, Creating a shader module>>

[[anchor-loading-a-shader-binary]]
*Loading a shader binary*

In order to create a shader module we need to load a compiled 'SPIR-V' data:

----
using MaybeShaderData = tl::expected<vector<char>, string>;

MaybeShaderData load_shader(string const & fileName)
{
	ifstream file{fileName, ios::ate | ios::binary}; // #a

	if (!file.is_open())
		return tl::make_unexpected("failed to open shader file");

	size_t const fileSize{static_cast<size_t>(file.tellg())};
	vector<char> buffer(fileSize);

	file.seekg(0);
	file.read(buffer.data(), fileSize);

	file.close();

	if (!file)
		return tl::make_unexpected("failed to read shader file");

	if (buffer.empty() || buffer.size() % 4 != 0) // #b
		return tl::make_unexpected("failed to read shader file");

	return buffer;
}
----

.. With a help of usual standard binary stream we load specified file. Here we search for the file in the same folder as executable.

.. Specification requires that the size of a code to be a multiple of 4 and here we check that everything is ok.

<<anchor-loading-a-shader-binary-back, Back>>

[[anchor-creating-a-shader-module]]
*Creating a shader module*

Another helper function:

----
MaybeShaderModule create_shader_module(VkDevice const device, vector<char> const * const shaderCode)
{
	assert(device);
	
	VkShaderModuleCreateInfo createInfo{get_shader_module_create_info(shaderCode)};
	
	VkShaderModule shaderModule{VK_NULL_HANDLE};
	if (vkCreateShaderModule(device, &createInfo, nullptr, &shaderModule) != VK_SUCCESS)
		return make_unexpected("failed to create shader module");
	
	return shaderModule;
}
----

As usual I need a structure first:

----
VkShaderModuleCreateInfo get_shader_module_create_info(vector<char> const * const shaderCode)
{
	assert(shaderCode);
	assert(!shaderCode->empty());
	assert(shaderCode->size() % 4 == 0);
	
	VkShaderModuleCreateInfo info{};
	info.sType = VK_STRUCTURE_TYPE_SHADER_MODULE_CREATE_INFO;
	info.pNext = nullptr;
	info.flags = 0;
	info.codeSize = shaderCode->size();
	info.pCode = reinterpret_cast<uint32_t const *>(shaderCode->data()); // #a
	
	return info;
}
----

.. Rather strange that the code should be passed as a pointer to `uint32_t` instead of expected pointer to `char`. A code with reinterpret casting always looks very suspicious to me but I double checked - there's no undefined behavior.

With the structure a can call `vkCreateShaderModule` to create a shader module.

<<anchor-creating-a-shader-module-back, Back>>

This steps should be repeated for every shader type. Since they are identical I will not describe them.

One more thing must be said about the shaders. Previously I wrote that each shader source should be compiled with a special tool called `glslangValidator`. It is very tedious to recompile each shader after a tine change so it would be cool to add shader compilation as a part of the build process. I wrote a CMake function that creates a target for provided shaders and adds it as a dependency to a main application so if something changed the data will be recompiled during the normal application build (or you can build each target separately if you wish).

----
function(addCompileShadersCommand)
    cmake_parse_arguments(addCompileShadersCommand "" "TARGET_NAME;OUTPUT_DIR" "SHADERS" ${ARGN})

    if(NOT addCompileShadersCommand_TARGET_NAME)
        message(FATAL_ERROR "Provide unique target name")
    endif()

    if(NOT addCompileShadersCommand_SHADERS)
        message(FATAL_ERROR "At least one shader file name should be provided")
    endif()

    set(FILE_NAMES "")
    set(OUTPUT_PATHS "")

    foreach(shader ${addCompileShadersCommand_SHADERS})
        get_filename_component(VAR ${shader} NAME_WE)
        list(APPEND FILE_NAMES ${VAR})
        list(APPEND OUTPUT_PATHS ${addCompileShadersCommand_OUTPUT_DIR}/${VAR}.spv)

        add_custom_command(OUTPUT ${addCompileShadersCommand_OUTPUT_DIR}/${VAR}.spv
                COMMAND ${GLSL_VALIDATOR} -V ${shader} -o ${addCompileShadersCommand_OUTPUT_DIR}/${VAR}.spv
                DEPENDS ${shader}
                )
    endforeach()

    add_custom_target(${addCompileShadersCommand_TARGET_NAME}
            DEPENDS ${OUTPUT_PATHS}
            COMMENT "Compiling ${FILE_NAMES}"
            )

    add_dependencies(teapot ${addCompileShadersCommand_TARGET_NAME})
endfunction()
----

The function expects a target name, an output directory and a list of shader files. And it's called like this:

----
addCompileShadersCommand(TARGET_NAME shaders
        OUTPUT_DIR ${CMAKE_BINARY_DIR}/bin
        SHADERS
        ${CMAKE_CURRENT_SOURCE_DIR}/resources/VertexShader.vert
        ${CMAKE_CURRENT_SOURCE_DIR}/resources/TesselationControlShader.tesc
        ${CMAKE_CURRENT_SOURCE_DIR}/resources/TesselationEvaluationShader.tese
        ${CMAKE_CURRENT_SOURCE_DIR}/resources/FragmentShader.frag
        )
----

Of cource it's possible to create a separate target for every shader but I decided to place everything into one.

<<anchor-creating-shader-modules-back, Back>>