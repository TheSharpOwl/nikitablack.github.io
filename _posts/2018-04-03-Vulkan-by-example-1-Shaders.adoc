= Vulkan by example 1 - Shaders
:hp-tags: c++, vulkan, glsl

In the https://TODO[previous lesson] we made all necessary preparations to start exploring vulkan. Here is the diagramm of the current state of the application:

[picture]

The diagramm is pretty empty now but it will grow as we progress through tutorials. For now it's enough to know that there's a CPU, which controls the application and sends commands to the GPU; a GPU itself, which do magic and produces nice pictures (not necessarily); a window which should these pictures to show. The window put in a separate category because the presentation of the picture controlled by an OS and not by an application or a GPU.

The main question for now - where to start? There are so many things to do, there are so many ways to do it. We start from the heart of every graphics application - shaders. After all this is exactly what GPU runs and we're here to programm the GPU. In the app we will use 4 shader stages - Vertex, Tesselation Control, Tesselation Evaluation, Fragment. Let's step over all of these stages briefly explaining the purpose of each.

===== Vertex shader

https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/resources/VertexShader.vert[Vertex shader] is the first stage in the pipeline and it's pretty simple. Looking back to the teapot data I know what information needs to be passed - since I'm using patches I need to provide points describing them - `16` points for every patch.

A patch point arrives to the shader at *location 0* and simply passed through to the next stage. This stage will be executed for every point (vertex) provided. Since I use `28` patches `16` point each it will be called at least `28 * 16 = 448` times (it's not an important information - just for fun).

===== Tessellation control shader

The next shader - https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/resources/TesselationControlShader.tesc[tesselation control shader] -  is simple as well since it doesn't do a lot of work. But still it have a couple of interesting things. The first one is how the tesselation level (how many new triangles a tesselator should create) is updated. I decided to use the so called `Push Constant` - a feature that allows to pass a constant directly in a command buffer, for now read it as fast and simple way and later I'll explain what this means when we'll reach the actual code. As you can see the tesselation level is a float variable and it is somehow updated from the CPU.

Next we tell the GPU that this stage produces 16 control points for the patch, i.e. we doesn't change the amount (yes, this stage can generate new points as well as remove some). And the number of executions of this shader is equal to the number specified out poinst times number of patches, i.e. `28 * 16 = 448` in our case.

===== Tessellation Evaluation shader

The https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/resources/TesselationEvaluationShader.tese[tessellation evaluation shader] is the actual workhorse of the whole application - all the magic happens here.

First we specify tesselation rules: domain (`quad`), spacing (`fractional_odd_spacing`) and winding order (`cw` - clockwise). Next we define the patch information in the form of a buffer. Again, no information right now - just know that each patch should be transformed and colored (see previous lesson for more details why) and the information incoming as an array of `PatchData` at a *binding slot 0*. Also I need transformation matrices. I could provide one MVP-matrix and reduce the number of calculations but I want to show how to deal with multiple uniform buffers in `Vulkan`. That's why there are three matrices: model, view and projection. And they are *binded to slots 1, 2, and 3*.

Next is a scary math - calculation of a 3d point using a `gl_TessCoord` that came from the tesselator. Actually the math is not that complicated, I found https://www.gamasutra.com/view/feature/131755/curved_surfaces_using_bzier_.php[this gamasutra article] very good at explaining the theory behind curves. And the code itself (functions `bernsteinBasis()` and `evaluateBezier()`) I shamelesly took from http://www.gdcvault.com/play/1012740/direct3d[this gdc presentation].

The outputs of this shader are newly generated vertex position (built in `gl_Position` variable) and a color (which we send to the next stage in the *output location 0*). Since the entire patch colored with a solid color every vertex from the same patch will have the same attribute.

I think it's obvious that a number of executions of this shader is equal to a number vertices produced by the tesselator. So it depends on the tesselation factor, provided in a tesselation control shader.

===== Fragment shader

https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/resources/FragmentShader.frag]Fragment shader] is another one _"lazy"_ shader - the data is coming from the previous stage at *input location 0* and going to the *output location 0* (which is a swapchain image, the window surface).

Hurray! The application is almost done! Joking. Once I read the sentense which describes `Vulkan` in a nutshell: _"Show me your triangle in three months."_ So be patient. I'm planning to write `7` or `8` parts in total. Shaders were the easiest part, and all the remaining code we need to write should serve a single purpose - to make the shaders run. And run *correctly*. By correctness I mean that there should not be undefined behavior, data races, gpu stalls.

===== Finally some Vulkan

So we have some shaders written as text which I can't use directly. In `Vulkan` shaders have to be compiled to so called `SPIR-V` binary format and supplied to the API via `VkShaderModule`. I can create one with `vkCreateShaderModule` function. Here's the declaration of this function:

----
VkResult vkCreateShaderModule(
    VkDevice                                    device,
    const VkShaderModuleCreateInfo*             pCreateInfo,
    const VkAllocationCallbacks*                pAllocator,
    VkShaderModule*                             pShaderModule);
----

Last parameter (`pShaderModule`) is a return value I'm interesting in - yes, in `Vulkan` functions return a result of a call and the parameters we want to get are passed as pointers to be filled. Third parameter (`pAllocator`) used for custom allocation and *never* will be used in these lessons (always `nullptr`). Second parameter (`pCreateInfo`) is an information which describes a shader and we can fill it right now. But the first parameter (`device`) is an unknown variable.

`VkDevice` is a software representation of `GPU`. I think about it like an instance of a real physical `GPU` - it is possible to have multiple instances of it in one application (though we will use only one). I can create a device with `vkCreateDevice` function:

----
VkResult vkCreateDevice(
    VkPhysicalDevice                            physicalDevice,
    const VkDeviceCreateInfo*                   pCreateInfo,
    const VkAllocationCallbacks*                pAllocator,
    VkDevice*                                   pDevice);
----

`pDevice` - return value, `pAllocator` - `nullptr`, `pCreateInfo` - some information, `physicalDevice` - again unknown.

Continuing our OOP the analogy `VkPhysicalDevice` is a class itself or a blueprint. It represents unique piece of hardware and can be used for obtaining some useful info, like capabilities of the `GPU`. It exist as a single instance and we can't create it, but can ask the API to give it to us with `vkEnumeratePhysicalDevices` call - this function enumerates available physical devices in a system:

----
VkResult vkEnumeratePhysicalDevices(
    VkInstance                                  instance,
    uint32_t*                                   pPhysicalDeviceCount,
    VkPhysicalDevice*                           pPhysicalDevices);
----

This will never end... Here again we see an unknown variable `instance`. Moreover, this function can return a list of *all* available devices in the system but we're interested only in one. For the application we need a GPU that supports tesselation and can output images to the operating system's presentation engine. Yes, it sounds weird but it looks like there are devices that can't render, at least in theory. In order to check device's _"presentability"_ I need some information about render surface. In `Vulkan` this information is stored in `VkSurfaceKHR` object. Fortunately with `GLFW` library getting of this object is an easy task:

----
VkResult glfwCreateWindowSurface(
    VkInstance instance,
    GLFWwindow * window,
    const VkAllocationCallbacks * allocator,
    VkSurfaceKHR * surface 
)
----

Again `VkInstance`. It is an entity that keeps the state of the application and which we can create with `vkCreateInstance` function:

----
VkResult vkCreateInstance(
    const VkInstanceCreateInfo*                 pCreateInfo,
    const VkAllocationCallbacks*                pAllocator,
    VkInstance*                                 pInstance);
----

Previously I wrote that `GLFW` library helps with creation of a surface. But this surface thing is special. `VkSurfaceKHR` - this `KHR` ending means that this object is not a part of a _standard_ vulkan, but object which can be obtained through *extensions*. Indeed, presentation is so OS specific that it's very hard to make it as a part of a standard. Or there could be some vendor specific extensions that adds some new functionality. There are instance-level extensions and device-level extensions. Extensions are just strings and for the surface we need to find out the extension name.

Finally no more unknown variables! But I already forgot why do I need all this... Ah, I wanted to create `Shader Modules`.

To summarize: here's the dependency chain:

----
VkShaderModule 游목 VkDevice 游목 VkPhysicalDevice 游목 VkSurfaceKHR 游목 VkInstance 游목 extensions
----

The https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/src/main.cpp[updated main function] now have calls to helper functions and we are going to visit each.

First is https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/src/vulkan/get_required_window_extensions.cpp[get_required_window_extensions]. Here the `glfw` helps a lot - the `glfwGetRequiredInstanceExtensions` hides from us the platform dependent code and returns the list of instance extensions, required for displaying a picture on a given platform.

Now when we have a list of extensions we are ready to create an instance, what we do in https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/src/vulkan/create_instance.cpp[create_instance] function. Here we can see the typical `Vulkan` approach to object creation - first we fill a special structure and second, provide this structure to a special function. Each structure has `sType` field and `pNext` field. The former is used to specify the type of object we want to create and obviously is different for different structures. The latter is used for some advanced things and never will be used in the tutorials. In the future I will not describe these fields for other objects. Also I will not write about fields which stay default for our case. For eexample, the field `flags` is not used so there's nothing to say about it. In this tutorial we don't need players, so the array is empty. and you are already familiar with the extensions. Next we call the `Vulkan` function which on success updates the `appData` and return either of the data or an error.

Next is https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/src/vulkan/create_surface.cpp[create_surface] function. Here again we use `glfw` to obtain a platform dependent object.

Now we can try to find a gpu device in 
https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/src/vulkan/get_physical_device.cpp[get_physical_device] function. it's a bit lengthy because we need to do more than a couple of things. First we need to get all available devices in the system. For that we use another typical `Vulkan` pattern for obtaining a list of something - we call a function with a ` nullptr` instead of a pointer to a list - this 
returns the total number of GPUs. The second call to the same function but with a list fills that list. Next we iterate over the devices trying to find one that works for us. In `check_device_suitability` we accept only a discrete device (one of my test machines have 2 GPUs and I want to use the more powerfull one so I ignore all non discrete adapters but if you are fine with integrated GPU you can remove this check) which supports tesselation, can draw in wireframe and supports all required device extensions. Device extensions are very similar to instance extensions we already discussed but work per device, not globally. We're not using any in this tutorial so the list is empty.

If the proper GPU was found we can continue to the next step. We can try to obtain some information which depends on a device and a surface. We start with the format of the surface we are going to render to. A given device and a surface can support multiple formats and we choose one in 
TODO[`get_device_surface_format`] helper function. First we get all supported formats. Next we check for the special case.  Here's a quote from the specification:

[source]
----
If pSurfaceFormats includes just one entry, whose value for format is VK_FORMAT_UNDEFINED, surface has no preferred format. In this case, the application can use any valid VkFormat value.
----

So if this condition is true we simply return `VK_FORMAT_B8G8R8A8_UNORM` as format and `VK_COLOR_SPACE_SRGB_NONLINEAR_KHR` as a color space. But if the condition is not true we iterate over all supported formats searching for the one we would like to work with. I like `VkSurfaceFormatKHR{VK_FORMAT_B8G8R8A8_UNORM, VK_COLOR_SPACE_SRGB_NONLINEAR_KHR}`.And if the desired format was not found we just return the first one from the list.

After the format was found we proceed to a surface pesent mode. As you know a monitor works with some fequency. For example, if the monitor have the frequency 60Hz it presents something on the screen every 1/60th of a second. The OS takes care about this presentation and all we need to do is to provide an image to show to the presentation engine. Also you may know that a monitor displays the entire picture not immediately at the some moment in time but fills the screen line by line from top to bottom for example, and do it very fast. Now think what can happen if, say the engine displayed a half of the picture from ta previous frame and we provided a new one? Right - the engine continues to present a picture but the new one, not the one it started with. So on the screen we have the combination of two images - so called _tearing_. Sometimes this is an admissible behavior and sometimes we want to avoid this. That's why we need to specify a presentation mode and do it in TODO['get_device_surface_present_mode'] helper function. First we get all available present modes for a given device and a surface. Next we choose the desired mode:

.. If we don't want the tearing in our application we tell the presentation engine to use it's internal queue - now the pending requests will be added to that queue and when the engine is ready to display it aquires the image from the begining of the queue by removing it. And we never see the tearing. `VK_PRESENT_MODE_MAILBOX_KHR` tells the engine to use a single-entry queue, meaning that the pending requests will be replaced by newest ones. This mode is what I want for the application but there's no guarantee that it is supported.

.. If we failed to find 'VK_PRESENT_MODE_MAILBOX_KHR' we try to find the next one - `VK_PRESENT_MODE_IMMEDIATE_KHR`. This mode does not use a queue so the tearing is possible. The mode is not guaranteed to be presented.

.. `VK_PRESENT_MODE_FIFO_KHR` is the only mode required to be supported so we return it if the previous attempts failed. This mode uses a queue as well but the size is not specified. The difference with `VK_PRESENT_MODE_MAILBOX_KHR` is that if the queue is full the application will be blocked until the engine removes available image and frees the place in the queue.

After the present mode we proceed to the next step where we get so called _queue families_ for the device. As you may know the CPU communicates with the GPU via commands. In 'Vulkan' we record these commands with special functions like `vkCmdDraw` or `vkCmdBindVertexBuffers` to a so called _command buffer_. After a set of commands is ready it needs to be sent to the device. We don't send it directly but put to some queue and the implementation later consumes that queue. Just think of these queues as connections between the CPU and the GPU. Vulkan defines 5 different family queues - `VK_QUEUE_GRAPHICS_BIT`, `VK_QUEUE_COMPUTE_BIT`, `VK_QUEUE_TRANSFER_BIT`, `VK_QUEUE_SPARSE_BINDING_BIT` and `VK_QUEUE_PROTECTED_BIT`. Each queue supports certain operations so we need to be carefull when submiting commands. The specification have a special section for every command where it specifies the queue the command can be used with. There's a guarantee from Vulkan that graphics queue (`VK_QUEUE_GRAPHICS_BIT`) supports transfer operations as well, so if you have to submit a transfer command you can do it with that queue, no need to create a transfer queue (`VK_QUEUE_TRANSFER_BIT`). But why do we need multiple queue families at all? Well, in theory using multiple queues can speed up the application - the submission of commands happens in parallel. And you know the word _parralel_ is the sinonym of _good_. How this works is described by Matt Pettineo (aka MJP) in these https://mynameismjp.wordpress.com/2018/03/06/breaking-down-barriers-part-1-whats-a-barrier/[amazing article series]. There's one more thing. Each queue family can have *multiple* queues, hence the name _family_. So, again in theory, you can use multiple queues from the same family to submit commands faster, you just need a proper GPU.

In TODO['get_device_graphics_and_present_queue_families'] helper function we first get all available families for a given device. Next we try to find proper family queue indices. In the application we will use 2 different queues - one for rendering and transfer operations and one for presenting. There are huges chances that your GPU have a queue the supports both of these operations but specification does not guarantee that so we check all possible cases. Anyway we check first for this case and if it was not successfull we try to find two separate queue families. If we could not find we continue with another device in the system or run to the nearest shop to buy a modern GPU. If both graphics and present queue families were found we return their indices as a tuple.

If everything went well we can finish with a device selection. But before that we get the device properties. The structure have a lot of useful information, like a device name or device limits (for example, how many compute groups the device can dispatch). And now we are done.

Now it's time for the https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/src/vulkan/create_logical_device.cpp[logical device]. Remember, the logical device is a software representation of a GPU and is needed almost for every other `Vulkan` function. First we tell a driver which queue families will be used with the selected gpu. When we selected a physical device we got a couple of queue families (graphics and present) in the form of indices. Together with the families we need to specify a number of actual queues and their priorities within a family. A queue with a higher priority theoretically can get more processing time than a queue with a lower priority. In the demo we use only one queue per family so we simply set priorities to 1. When the logical device is created the specified queues will be created as well. Next we enable device features. The application need `tessellationShader`, `fillModeNonSolid` and `vertexPipelineStoresAndAtomics` to be turned on.

NOTE: At the moment of writing the validation layers (this topic not covered yet) reports a false error - `Shader requires vertexPipelineStoresAndAtomics but is not enabled on the device`. Though if you look at the tesselation eveluation shader declaration you will see that I marked one of the buffers as `readonly`. This is indeed a bug and already was reported https://github.com/KhronosGroup/Vulkan-ValidationLayers/issues/73[here].

All this data I provide via the `VkDeviceCreateInfo` structure. I specify `deviceExtensions` as well but this array is empty since in first tutorials we don't need any. Finaly we call `vkCreateDevice`.

Haleluja! Now we have everything for our shaders. But wait, `Vulkan`can't read text files - it needs some shader binary data in the `SPIR-V` format. Previously I wrote that a shader source should be compiled with a special tool, for example with `glslangValidator`. It is very tedious to run a command line to recompile the shader after a tiny change so it would be cool to add shader compilation as a part of the build process. I wrote a https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/CMakeLists.txt#L54[CMake function] which creates targets for provided shaders and adds it as a dependency to a main application so if something changed the data will be recompiled during the normal application build (or you can build each target separately if you want). So after the build we have binaries for the shaders. We load them with `https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/src/vulkan/create_shader_modules.cpp#L8] helper function. Specification requires that the size of a blob to be a multiple of 4 and here we check that everything is ok. Now we create four shader modules in https://github.com/nikitablack/vulkan_by_example_2/blob/lesson_1/src/teapot/src/vulkan/create_shader_modules.cpp[`create_shader_modules`] function - one for every shader stage. 


