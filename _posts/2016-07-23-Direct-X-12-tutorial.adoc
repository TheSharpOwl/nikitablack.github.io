= DirectX 12 tutorial
:hp-tags: c++, directx12

===== Disclaimer!
I'm not an expert. When I started to learn directx 12 I already was quite comfortable with directx 11. Nevertheless it was very difficult for me to switch. And even after several months of learning I still have a feeling that I just scratched a surface. So I'm still learning and this post is a syncronization of my thoughts so far and it will contain questions. Thought I hope somebody will find it useful.

Directx 12 is low level, it have many concepts and in order to make your code work well you need to take into account a lot of things. You need to profile a lot. And you need to know hardware. For example you need to know that changing descriptor heaps is a heavy operation. I have no idea what happening in hardware and why it's expensive. I'm just following guidelines and trying to remember.

Also I assume that the reader have an experience with previous directx versions because I'll not explain in this post what is swapchain or backbuffer. You should be familar with tesselation - what are tesselation factors, what is a constant function, why do you need `hull` and `domain` shaders. Good overview of directx 11 tesselation can be found https://msdn.microsoft.com/en-us/library/windows/desktop/ff476340(v=vs.85).aspx[here]. Also you need to know basic windows programming because we need to create a window and I'll not explain how to do it. So let's jump directly into the stove.

In this tutorial we're going to render a teapot. But not just a static mesh, no. We'll render a tesselated teapot. Why did I chose to go this way? Well, because you can find in the web different _HelloWorld_ examples. I wanted to create somethig that covers different areas of api and at the same time is simple. So our final picture will look like this:

[picture]

We're going to use 16-point patches for the teapot. We'll provide control points positions in one vertex buffer and patch indicies in one index buffer. For colors and transforms (more on this later) we'll use structured buffers.

Usually directx tutorials follows the same pattern - d3d initialization, resource creation, rendering. I decided to go different way - first we'll create the most important part of the code and later will add different components to support it - one after another as required. And the most important part, by my opinion, is *shaders*. After all this is what we want the gpu to execute and later we'll create a code to serve our shaders. In order to write a shader we need to figure out what data we need. So let's first define it.

===== Teapot data

Since we're going to use tesselation we're not interested in "usual" mesh consisting of triangles. We need patches. Of course somebody already did it before so we can use the data. For example https://www.sjbaker.org/wiki/index.php?title=The_History_of_The_Teapot#The_Teapot_DataSet[here] the data set for 16-point patches. But we can't use this data as it is, we need to adjust it a little. This set doesn't have a bottom and it's and it's ok, we'll not use it either. But the existing patches describe only parts of the teapot. For example rim, body and lid describe only a quarter of a teapot and handle and spout describe only left half of this parts. So if we'll render only this set we'll get this results.

[picture]

There're several ways to fix it. One way is to use separate draw call for every part. This way we can render rim four times with different transformation. Another way is to draw a part once but use instancing. But we'll copy the data and render everything in one draw call. For this we'll duplicate the indices required number of times and also provide a transformation for every part. Let's take a rim as an example again. Instead of having one patch for the quarter we'll have 4 patches for the entire circle, that means `16 * 4 = 64` indices for this part. In the shader knowing the patch id we can apply a transform. In this case rotate it around an axis by `0`, `90`, `180` and `270` degrees. All that means that together with points positions and indices we need to provide a transformation data as. Additionaly to visually separate patches we'll use different colors which, as you guessed, also should be provided as a separate data. In total we'll have `28` patches - list of points (some points are shared between patches - that's why we need indices), list of indices (`28 * 16`), list of transforms (`28` matrices) and list of colors (`28` randomly generated rgb colors). Final data can be found https://github.com/nikitablack/directx-12/blob/master/TeapotTutorial/TeapotTutorial/TeapotData.cpp[here].

===== Shaders
In our example we'll use `vertex`, `hull`, `domain` and `pixel` shaders.

*Vertex shader*

The first shader in our pipeline is the `vertex` shader. All it's do is accepts control point position from the application and passes it to the `hull` shader.

[source,cpp]
----
struct VertexData
{
	float3 pos : POSITION;
};

struct VertexToHull
{
	float3 pos : POSITION;
};

VertexToHull main(VertexData input)
{
	VertexToHull output;
	output.pos = input.pos;

	return output;
}
----

Just for remainder - the `vertex` shader will be called once for every vertex (suddenly!). For 28 patches (and this is the number of patches used for the model) and 16 points each this is 448 times.

*Hull shader*

This shader, as you already know, accepts control point position from the `vertex` shader and also some data from the application in the form of constants which we'll use as tesseltion factors for the edge and inside of the patch.

[source,cpp]
----
#define NUM_CONTROL_POINTS 16

struct PatchTesselationFactors
{
	int edge;
	int inside;
};
ConstantBuffer<PatchTesselationFactors> tessFactors : register(b0);

struct VertexToHull
{
	float3 pos : POSITION;
};

struct PatchConstantData
{
	float edgeTessFactor[4] : SV_TessFactor;
	float insideTessFactor[2] : SV_InsideTessFactor;
};

struct HullToDomain
{
	float3 pos : POSITION;
};

PatchConstantData CalculatePatchConstants()
{
	PatchConstantData output;

	output.edgeTessFactor[0] = tessFactors.edge;
	output.edgeTessFactor[1] = tessFactors.edge;
	output.edgeTessFactor[2] = tessFactors.edge;
	output.edgeTessFactor[3] = tessFactors.edge;
	output.insideTessFactor[0] = tessFactors.inside;
	output.insideTessFactor[1] = tessFactors.inside;

	return output;
}

[domain("quad")]
[partitioning("fractional_odd")]
[outputtopology("triangle_cw")]
[outputcontrolpoints(NUM_CONTROL_POINTS)]
[patchconstantfunc("CalculatePatchConstants")]
HullToDomain main(InputPatch<VertexToHull, NUM_CONTROL_POINTS> input, uint i : SV_OutputControlPointID)
{
	HullToDomain output;
	output.pos = input[i].pos;

	return output;
}
----

Here you see that the patch outputs 16 control points. Also note the new hlsl 5.1 syntax for the constant buffer `ConstantBuffer<PatchTesselationFactors> tessFactors : register(b0);`. Thought you can use the old syntax I like the new one more. Beyond this the shader is a simple pass-through, like a `vertex` shader.

This shader will be invoked 28 number of times (by the number of patches).

*Domain shader*

Finally we arrived to the place of interest. Basically this is the place where all the work is done in our program.

[source,cpp]
----
#define NUM_CONTROL_POINTS 16

struct ConstantBufferPerObj
{
	row_major float4x4 wvpMat;
};
ConstantBuffer<ConstantBufferPerObj> constPerObject : register(b0);

struct PatchTransform
{
	row_major float4x4 transform;
};
StructuredBuffer<PatchTransform> patchTransforms : register(t0);

struct PatchColor
{
	float3 color;
};
StructuredBuffer<PatchColor> patchColors : register(t1);

struct PatchConstantData
{
	float edgeTessFactor[4] : SV_TessFactor;
	float insideTessFactor[2] : SV_InsideTessFactor;
};

struct HullToDomain
{
	float3 pos : POSITION;
};

struct DomainToPixel
{
	float4 pos : SV_POSITION;
	float3 color : COLOR;
};

float4 BernsteinBasis(float t)
{
	float invT = 1.0f - t;
	return float4(invT * invT * invT,	// (1-t)3
		3.0f * t * invT * invT,			// 3t(1-t)2
		3.0f * t * t * invT,			// 3t2(1-t)
		t * t * t);						// t3
}

float3 evaluateBezier(const OutputPatch<HullToDomain, NUM_CONTROL_POINTS> bezpatch, float4 basisU, float4 basisV)
{
	float3 value = float3(0, 0, 0);
	value = basisV.x * (bezpatch[0].pos * basisU.x + bezpatch[1].pos * basisU.y + bezpatch[2].pos * basisU.z + bezpatch[3].pos * basisU.w);
	value += basisV.y * (bezpatch[4].pos * basisU.x + bezpatch[5].pos * basisU.y + bezpatch[6].pos * basisU.z + bezpatch[7].pos * basisU.w);
	value += basisV.z * (bezpatch[8].pos * basisU.x + bezpatch[9].pos * basisU.y + bezpatch[10].pos * basisU.z + bezpatch[11].pos * basisU.w);
	value += basisV.w * (bezpatch[12].pos * basisU.x + bezpatch[13].pos * basisU.y + bezpatch[14].pos * basisU.z + bezpatch[15].pos * basisU.w);

	return value;
}

[domain("quad")]
DomainToPixel main(PatchConstantData input, float2 domain : SV_DomainLocation, const OutputPatch<HullToDomain, NUM_CONTROL_POINTS> patch, uint patchID : SV_PrimitiveID)
{
	// Evaluate the basis functions at (u, v)
	float4 basisU = BernsteinBasis(domain.x);
	float4 basisV = BernsteinBasis(domain.y);

	// Evaluate the surface position for this vertex
	float3 localPos = evaluateBezier(patch, basisU, basisV);

	float4x4 transform = patchTransforms[patchID].transform;
	float4 localPosTransformed = mul(float4(localPos, 1.0f), transform);

	DomainToPixel output;
	output.pos = mul(localPosTransformed, constPerObject.wvpMat);
	output.color = patchColors[patchID].color;

	return output;
}
----

Going from the top we can see that we're operating on the same 16 point patch, we have a constant buffer for the patch`s world-view-projection, structured buffer for the patch transform (more on this in a next section), structured buffer for the patch color. On practice we can and should use one structured buffer for both transforms and colors but I deliberately split it in two to show how we can assign resources through the root table (more on this later). This data we're receiving from the application.

NOTE: There're some places where I chose non optimal path and did this by purpose - maybe for simplicity or maybe to show different possibilities of the api. In such places I added a note. But if you found a place where things done poorly and there's no note around - that means I simply missed something and it would be great if you point this in the comment so I can make a fix.

There're also structs: `PatchConstantData` and `HullToDomain` - data from the `hull` shader (remember that position is a pass through from the `vertex` shader which also passes it through from the input assembler), `DomainToPixel` - the data we're passing further the pipeline - to the `pixel` shader.

Next is a pure math - in the `main()` function we have a list of control points (16 points) and we need to sample them so we can assign a position to the newly generated by tesselator vertex. The good overview of the math behind you can find http://www.gamasutra.com/view/feature/131755/curved_surfaces_using_bzier_.php[here]. Also http://www.gdcvault.com/play/1012740/direct3d[this presentation] is a very good reading about patch tesselation in directx 11 (I took the most shader code from there to be honest).

So what are we doing in the `main()` function? You can see that the function's signature is pretty big. The first 3 parameters are pretty standard - the constant data which we defined in the `hull` shader (not used here), `uv` coordinates for our point in the square (quad) domain - generated by tesselator, and initial patch information from the hull shader. The last parameter - `PatchID` with special semantics is worth paying attention. In our demo we know the total number of patches for the teapot model - 28. And we want to apply some parameters to the entire patch, for example to color the entire patch with the same color. That means that for every generated vertex in the same patch we need to assign the same color information. And this is where `SV_PrimitiveID` semantics will come to the rescue - for every vertex of the same patch (no matter how many vertices were generated - 4 or 200) this value will be the same. The first patch will get id of `0`, second patch - `1` and so on. Probably you can see where we're going - we can create some static data which we can sample with patch id and get the patch-unique information.

First we're finding the vertex position in patch space. Next with the help of the patch id we're obtaining some transform (next section will tell why) and finding the final local space matrix. Next we're transforming the vertex to the homogenious space by multiplying it on world-view-projection matrix. In the final step we're sampling the color structured buffer (also - next section) and sending this data to our last programmable stage - `pixel` shader.

This function will be called for every generated vertex (generated by tesselator). The number of generated vertices depends on the tesselation factors (edge and inside for the quad patch) and partitioning scheme (`[partitioning("fractional_odd")]` in the `hull` shader).

*Pixel shader*

[source,cpp]
----
struct DomainToPixel
{
	float4 pos : SV_POSITION;
	float3 color : COLOR;
};

float4 main(DomainToPixel input) : SV_TARGET
{
	return float4(input.color, 1.0f);
}
----

Very simple shader, don't even need to be discussed.

That's basically it - we have a program and we need to make gpu to run it. All other code are just instructions to the gpu to use correct stages, correct data etc.
 