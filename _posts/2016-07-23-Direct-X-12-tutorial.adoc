= DirectX 12 tutorial
:hp-tags: c++, directx12

===== Disclaimer!
I'm not an expert. When I started to learn `directx 12` I already was quite comfortable with `directx 11`. Nevertheless it was very difficult for me to switch. And even after several months of learning I still have a feeling that I just scratched a surface. I'm still learning and this post is a syncronization of my thoughts so far and it will contain questions. Thought I hope somebody will find it useful.

`Directx 12` is low level, it have many concepts and in order to make your code work well you need to take into account a lot of things. You need to profile a lot. And you need to know a hardware. For example you need to know that changing descriptor heaps is a heavy operation. I have no idea what's happening in hardware and why it's expensive. I'm just following guidelines trying to remember and reading gpu specs in parallel.

Also I assume that the reader have an experience with previous directx versions because I'll not explain in this post what is swapchain or backbuffer. You should be familar with tesselation - what are tesselation factors, what is a constant function, why do you need `hull` and `domain` shaders. Good overview of `directx 11` tesselation can be found https://msdn.microsoft.com/en-us/library/windows/desktop/ff476340(v=vs.85).aspx[here]. Also you need to know basic windows programming because we need to create a window and I'll not explain how to do it.

In this tutorial we're going to render a teapot. But not just a static mesh, no. We'll render a tesselated teapot. Why did I chose this? Well, because you can find in the web a plenty of different _HelloWorld_ examples. I didn't want to create another _HelloWorld_ but somethig that covers different areas of the api and at the same time is simple.

[picture]

We're going to use `16`-point patches for the teapot. We'll provide control points positions in one vertex buffer and patch indicies in one index buffer. For colors and transforms (more on this later) we'll use structured buffers.

Usually directx tutorials follow the same pattern - initialization, resource creation, rendering. I decided to go different way - first we'll create the most important part of the code and later will add different components to support it - one after another as required. And the most important part, by my opinion, is *shaders*. After all this is what we want the gpu to execute. This approach helped me to tie different parts of the api and undesrtand how they related to each other. In order to write a shader we need to figure out what data we need. So let's first define it.

===== Teapot data

Since we're going to use tesselation we're not interested in _"usual"_ mesh consisting of triangles. We need patches. Of course somebody already described the teapot and we can use this data. For example https://www.sjbaker.org/wiki/index.php?title=The_History_of_The_Teapot#The_Teapot_DataSet[here] is the set of `16`-point patches. Unfortunatelly we can't use this data as it is and we need to adjust it a little. This set doesn't have a bottom - -it's ok, we'll not use it either. But the existing patches describe only parts of the teapot. For example _rim_, _body_ and _lid_ describe only a quarter of a teapot and _handle_ and _spout_ describe only half of this parts. So if we'll render this set we'll get this:

[picture]

There're several ways to fix it. One way is to use separate draw call for every part. This way we can render rim four times with different transformation. Another way is to draw a part once but use instancing. But we'll copy the data and render everything in one draw call. For this we'll duplicate the indices required number of times and also provide a transformation for every part. Let's take a rim as an example again. Instead of having one patch for the quarter we'll have `4` patches for the entire circle, that means `16 * 4 = 64` indices for this part. In the shader knowing the patch id we can apply a transform. In this case rotate it around an axis by `0`, `90`, `180` and `270` degrees. All that means that together with points positions and indices we need to provide a transformation data as. Additionaly to visually separate patches we'll use different colors which, as you guessed, also should be provided as a separate data. In total we'll have `28` patches - list of points (some points are shared between patches - that's why we need indices), list of indices (`28 * 16`), list of transforms (`28` matrices) and list of colors (`28` randomly generated rgb colors). Final data can be found https://github.com/nikitablack/directx-12/blob/master/TeapotTutorial/TeapotTutorial/TeapotData.cpp[here].

===== Shaders
In our example we'll use `vertex`, `hull`, `domain` and `pixel` shaders.

*Vertex shader*

The first shader in our pipeline is the `vertex` shader. All it's do is accepts control point position from the application and passes it to the `hull` shader. Because of it's simplicity I'll not provide it here but you can observe it in https://github.com/nikitablack/directx-12/blob/master/TeapotTutorial/TeapotTutorial/VertexShader.hlsl[github].

Just for remainder - the `vertex` shader will be called once for every control point in the patch. For `28` patches (recall that this is the number of patches used for the model) `16` points each this is `448` times.

*Hull shader*

This shader, as you already know, receives control point position from the `vertex` shader and also some data from the application in the form of constants which we'll use as tesseltion factors for the edge and inside of the patch.

[source,cpp]
----
#define NUM_CONTROL_POINTS 16

struct PatchTesselationFactors
{
	int edge;
	int inside;
};
ConstantBuffer<PatchTesselationFactors> tessFactors : register(b0);

struct VertexToHull
{
	float3 pos : POSITION;
};

struct PatchConstantData
{
	float edgeTessFactor[4] : SV_TessFactor;
	float insideTessFactor[2] : SV_InsideTessFactor;
};

struct HullToDomain
{
	float3 pos : POSITION;
};

PatchConstantData calculatePatchConstants()
{
	PatchConstantData output;

	output.edgeTessFactor[0] = tessFactors.edge;
	output.edgeTessFactor[1] = tessFactors.edge;
	output.edgeTessFactor[2] = tessFactors.edge;
	output.edgeTessFactor[3] = tessFactors.edge;
	output.insideTessFactor[0] = tessFactors.inside;
	output.insideTessFactor[1] = tessFactors.inside;

	return output;
}

[domain("quad")]
[partitioning("integer")]
[outputtopology("triangle_cw")]
[outputcontrolpoints(NUM_CONTROL_POINTS)]
[patchconstantfunc("calculatePatchConstants")]
HullToDomain main(InputPatch<VertexToHull, NUM_CONTROL_POINTS> input, uint i : SV_OutputControlPointID)
{
	HullToDomain output;
	output.pos = input[i].pos;

	return output;
}
----

Here you see that the patch outputs the same `16` control points, uses `integer` partitioning and `quad` domain. Also note the new `hlsl 5.1` syntax for the constant buffer `ConstantBuffer<PatchTesselationFactors> tessFactors : register(b0);`. Thought you can use the old syntax I like the new one more. Beyond this the shader is a simple pass-through, like a `vertex` shader.

This shader will be invoked `28` number of times (by the number of patches).

*Domain shader*

Finally we arrived to the place of interest. Basically this is the place where all the work is done in our program.

[source,cpp]
----
#define NUM_CONTROL_POINTS 16

struct ConstantBufferPerObj
{
	row_major float4x4 wvpMat;
};
ConstantBuffer<ConstantBufferPerObj> constPerObject : register(b0);

struct PatchTransform
{
	row_major float4x4 transform;
};
StructuredBuffer<PatchTransform> patchTransforms : register(t0);

struct PatchColor
{
	float3 color;
};
StructuredBuffer<PatchColor> patchColors : register(t1);

struct PatchConstantData
{
	float edgeTessFactor[4] : SV_TessFactor;
	float insideTessFactor[2] : SV_InsideTessFactor;
};

struct HullToDomain
{
	float3 pos : POSITION;
};

struct DomainToPixel
{
	float4 pos : SV_POSITION;
	float3 color : COLOR;
};

float4 BernsteinBasis(float t)
{
	float invT = 1.0f - t;
	return float4(invT * invT * invT,	// (1-t)3
		3.0f * t * invT * invT,		// 3t(1-t)2
		3.0f * t * t * invT,		// 3t2(1-t)
		t * t * t);			// t3
}

float3 evaluateBezier(const OutputPatch<HullToDomain, NUM_CONTROL_POINTS> bezpatch, float4 basisU, float4 basisV)
{
	float3 value = float3(0, 0, 0);
	value = basisV.x * (bezpatch[0].pos * basisU.x + bezpatch[1].pos * basisU.y + bezpatch[2].pos * basisU.z + bezpatch[3].pos * basisU.w);
	value += basisV.y * (bezpatch[4].pos * basisU.x + bezpatch[5].pos * basisU.y + bezpatch[6].pos * basisU.z + bezpatch[7].pos * basisU.w);
	value += basisV.z * (bezpatch[8].pos * basisU.x + bezpatch[9].pos * basisU.y + bezpatch[10].pos * basisU.z + bezpatch[11].pos * basisU.w);
	value += basisV.w * (bezpatch[12].pos * basisU.x + bezpatch[13].pos * basisU.y + bezpatch[14].pos * basisU.z + bezpatch[15].pos * basisU.w);

	return value;
}

[domain("quad")]
DomainToPixel main(PatchConstantData input, float2 domain : SV_DomainLocation, const OutputPatch<HullToDomain, NUM_CONTROL_POINTS> patch, uint patchID : SV_PrimitiveID)
{
	// Evaluate the basis functions at (u, v)
	float4 basisU = BernsteinBasis(domain.x);
	float4 basisV = BernsteinBasis(domain.y);

	// Evaluate the surface position for this vertex
	float3 localPos = evaluateBezier(patch, basisU, basisV);

	float4x4 transform = patchTransforms[patchID].transform;
	float4 localPosTransformed = mul(float4(localPos, 1.0f), transform);

	DomainToPixel output;
	output.pos = mul(localPosTransformed, constPerObject.wvpMat);
	output.color = patchColors[patchID].color;

	return output;
}
----

Going from top we see that we're operating on the same `16` point patch, we have a constant buffer for the teapot`s world-view-projection transform, structured buffer for the patch transform and structured buffer for the patch color. On practice we can use one structured buffer for both transforms and colors but I deliberately split it in two to show how we can assign resources through the root table (more on this later). This data we're receiving from the application.

NOTE: There're some places where I chose non optimal path and did this by purpose - maybe for simplicity or maybe to show different possibilities of the api. In such places I added a note. But if you found a place where things done poorly and there's no note around - that means I simply missed something and it would be great if you point this in the comment so I can make a fix.

There're also structs: `PatchConstantData` and `HullToDomain` - data from the `hull` shader (remember that position is a pass through from the `vertex` shader which also passes it through from the input assembler), `DomainToPixel` - the data we're passing further the pipeline - to the `pixel` shader.

Next is a pure math - in the `main()` function we have a list of control points for one patch (`16` points) and we need to sample them so we can assign a position to the new vertex generated by tesselator. The good overview of the math behind you can find http://www.gamasutra.com/view/feature/131755/curved_surfaces_using_bzier_.php[here]. Also http://www.gdcvault.com/play/1012740/direct3d[this presentation] is a very good reading about patch tesselation in `directx 11` (I took the most shader code from there to be honest).

So what are we doing in the `main()` function? The first `3` function parameters are pretty standard - the constant data which we defined in the `hull` shader (not used here, but have to be provided), `uv` coordinates for our point in the square (quad) domain - generated by tesselator, and initial patch information from the hull shader. The last parameter - `PatchID` with special semantics is worth paying attention. As you remember, in our demo we have the total number of patches equal to `28`. And we want to apply some parameters to the entire patch, for example a color. That means that for every generated vertex in the same patch we need to assign the same color information and pass it to the `pixel` shader. And this is where `SV_PrimitiveID` semantics will come to the rescue - for every vertex of the same patch (no matter how many vertices were generated) this value will be the same. The first patch will get id of `0`, second patch - `1` and so on. One thing worth to remember - all patches should be rendered in one draw call. Every new draw call resets the id (as well as new instance in instance drawing).

First we're finding the vertex position in patch space. Next with the help of the patch id we're obtaining some transform (next section will tell why) and finding the final local space matrix. Next we're transforming the vertex to the homogenious space by multiplying it on world-view-projection matrix. In the final step we're sampling the color structured buffer (also - next section) and sending this data to our last programmable stage - `pixel` shader.

This function will be called for every generated vertex (generated by tesselator). The number of generated vertices depends on the tesselation factors (edge and inside for the quad patch) and partitioning scheme (`[partitioning("fractional_odd")]` in the `hull` shader).

*Pixel shader*

[source,cpp]
----
struct DomainToPixel
{
	float4 pos : SV_POSITION;
	float3 color : COLOR;
};

float4 main(DomainToPixel input) : SV_TARGET
{
	return float4(input.color, 1.0f);
}
----

Very simple shader, don't even need to be discussed.

That's basically it - we have a program and we need to make gpu to run it. All other code are just instructions to the gpu to use correct stages, correct data etc.
 