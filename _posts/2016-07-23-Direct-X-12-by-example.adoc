= DirectX 12 by example
:hp-tags: c++, directx12

===== Disclaimer!
I'm not an expert. When I started to learn `directx 12` I already was quite comfortable with `directx 11`. Nevertheless it was very difficult for me to switch. And even after several months of learning I still have a feeling that I just scratched a surface. I'm still learning and this post is a syncronization of my thoughts so far and it will contain questions. Thought I hope somebody will find it useful.

`Directx 12` is low level, it have many concepts and in order to make your code work well you need to take into account a lot of things. You need to profile a lot. And you need to know a hardware. For example you need to know that changing descriptor heaps is a heavy operation. I have no idea what's happening in hardware and why it's expensive. I'm just following guidelines trying to remember and reading gpu specs in parallel.

Also I assume that the reader have an experience with previous directx versions because I'll not explain in this post what is swapchain or backbuffer. You should be familar with tesselation - what are tesselation factors, what is a constant function, why do you need `hull` and `domain` shaders. Good overview of `directx 11` tesselation can be found https://msdn.microsoft.com/en-us/library/windows/desktop/ff476340(v=vs.85).aspx[here]. Also you need to know basic windows programming because we need to create a window and I'll not explain how to do it.

In this tutorial we're going to render a teapot. But not just a static mesh, no. We'll render a tesselated teapot. Why did I chose this? Well, because you can find in the web a plenty of different _HelloWorld_ examples. I didn't want to create another _HelloWorld_ but somethig that covers different areas of the api and at the same time is simple.

[picture]

We're going to use `16`-point patches for the teapot. We'll provide control points positions in one vertex buffer and patch indicies in one index buffer. For colors and transforms (more on this later) we'll use structured buffers.

Usually directx tutorials follow the same pattern - initialization, resource creation, rendering. I decided to go different way - first we'll create the most important part of the code and later will add different components to support it - one after another as required. And the most important part, by my opinion, is *shaders*. After all this is what we want the gpu to execute. This approach helped me to tie different parts of the api and undesrtand how they related to each other. In order to write a shader we need to figure out what data we need. So let's first define it.

===== Teapot Data

Since we're going to use tesselation we're not interested in _"usual"_ mesh consisting of triangles. We need patches. Of course somebody already described the teapot and we can use this data. For example https://www.sjbaker.org/wiki/index.php?title=The_History_of_The_Teapot#The_Teapot_DataSet[here] is the set of `16`-point patches. Unfortunatelly we can't use this data as it is and we need to adjust it a little. This set doesn't have a bottom - -it's ok, we'll not use it either. But the existing patches describe only parts of the teapot. For example _rim_, _body_ and _lid_ describe only a quarter of a teapot and _handle_ and _spout_ describe only half of this parts. So if we'll render this set we'll get this:

[picture]
image::teapot_tutorial/teapot_quarter.png[]

There're several ways to fix it. One way is to use separate draw call for every part. This way we can render rim four times with different transformation. Another way is to draw a part once but use instancing. But we'll copy the data and render everything in one draw call. For this we'll duplicate the indices required number of times and also provide a transformation for every part. Let's take a rim as an example again. Instead of having one patch for the quarter we'll have `4` patches for the entire circle, that means `16 * 4 = 64` indices for this part. In the shader knowing the patch id we can apply a transform. In this case rotate it around an axis by `0`, `90`, `180` and `270` degrees. All that means that together with points positions and indices we need to provide a transformation data as. Additionaly to visually separate patches we'll use different colors which, as you guessed, also should be provided as a separate data. In total we'll have `28` patches - list of points (some points are shared between patches - that's why we need indices), list of indices (`28 * 16`), list of transforms (`28` matrices) and list of colors (`28` randomly generated rgb colors). Final data can be found https://github.com/nikitablack/directx-12/blob/master/TeapotTutorial/TeapotTutorial/TeapotData.cpp[here].

===== Shaders
In our example we'll use `vertex`, `hull`, `domain` and `pixel` shaders.

*Vertex shader*

The first shader in our pipeline is the `vertex` shader. All it's do is accepts control point position from the application and passes it to the `hull` shader. Because of it's simplicity I'll not provide it here but you can observe it in https://github.com/nikitablack/directx-12/blob/master/TeapotTutorial/TeapotTutorial/VertexShader.hlsl[github].

Just for remainder - the `vertex` shader will be called once for every control point in the patch. For `28` patches (recall that this is the number of patches used for the model) `16` points each this is `448` times.

*Hull shader*

This shader, as you already know, receives control point position from the `vertex` shader and also some data from the application in the form of constants which we'll use as tesseltion factors for the edge and inside of the patch.

[source,cpp]
----
#define NUM_CONTROL_POINTS 16

struct PatchTesselationFactors
{
	int edge;
	int inside;
};
ConstantBuffer<PatchTesselationFactors> tessFactors : register(b0);

struct VertexToHull
{
	float3 pos : POSITION;
};

struct PatchConstantData
{
	float edgeTessFactor[4] : SV_TessFactor;
	float insideTessFactor[2] : SV_InsideTessFactor;
};

struct HullToDomain
{
	float3 pos : POSITION;
};

PatchConstantData calculatePatchConstants()
{
	PatchConstantData output;

	output.edgeTessFactor[0] = tessFactors.edge;
	output.edgeTessFactor[1] = tessFactors.edge;
	output.edgeTessFactor[2] = tessFactors.edge;
	output.edgeTessFactor[3] = tessFactors.edge;
	output.insideTessFactor[0] = tessFactors.inside;
	output.insideTessFactor[1] = tessFactors.inside;

	return output;
}

[domain("quad")]
[partitioning("integer")]
[outputtopology("triangle_cw")]
[outputcontrolpoints(NUM_CONTROL_POINTS)]
[patchconstantfunc("calculatePatchConstants")]
HullToDomain main(InputPatch<VertexToHull, NUM_CONTROL_POINTS> input, uint i : SV_OutputControlPointID)
{
	HullToDomain output;
	output.pos = input[i].pos;

	return output;
}
----

Here you see that the patch outputs the same `16` control points, uses `integer` partitioning and `quad` domain. Also note the new `hlsl 5.1` syntax for the constant buffer `ConstantBuffer<PatchTesselationFactors> tessFactors : register(b0);`. Thought you can use the old syntax I like the new one more. Beyond this the shader is a simple pass-through, like a `vertex` shader.

This shader will be invoked `28` number of times (by the number of patches).

*Domain shader*

Finally we arrived to the place of interest. Basically this is the place where all the work is done in our program.

[source,cpp]
----
#define NUM_CONTROL_POINTS 16

struct ConstantBufferPerObj
{
	row_major float4x4 wvpMat;
};
ConstantBuffer<ConstantBufferPerObj> constPerObject : register(b0);

struct PatchTransform
{
	row_major float4x4 transform;
};
StructuredBuffer<PatchTransform> patchTransforms : register(t0);

struct PatchColor
{
	float3 color;
};
StructuredBuffer<PatchColor> patchColors : register(t1);

struct PatchConstantData
{
	float edgeTessFactor[4] : SV_TessFactor;
	float insideTessFactor[2] : SV_InsideTessFactor;
};

struct HullToDomain
{
	float3 pos : POSITION;
};

struct DomainToPixel
{
	float4 pos : SV_POSITION;
	float3 color : COLOR;
};

float4 BernsteinBasis(float t)
{
	float invT = 1.0f - t;
	return float4(invT * invT * invT,	// (1-t)3
		3.0f * t * invT * invT,		// 3t(1-t)2
		3.0f * t * t * invT,		// 3t2(1-t)
		t * t * t);			// t3
}

float3 evaluateBezier(const OutputPatch<HullToDomain, NUM_CONTROL_POINTS> bezpatch, float4 basisU, float4 basisV)
{
	float3 value = float3(0, 0, 0);
	value = basisV.x * (bezpatch[0].pos * basisU.x + bezpatch[1].pos * basisU.y + bezpatch[2].pos * basisU.z + bezpatch[3].pos * basisU.w);
	value += basisV.y * (bezpatch[4].pos * basisU.x + bezpatch[5].pos * basisU.y + bezpatch[6].pos * basisU.z + bezpatch[7].pos * basisU.w);
	value += basisV.z * (bezpatch[8].pos * basisU.x + bezpatch[9].pos * basisU.y + bezpatch[10].pos * basisU.z + bezpatch[11].pos * basisU.w);
	value += basisV.w * (bezpatch[12].pos * basisU.x + bezpatch[13].pos * basisU.y + bezpatch[14].pos * basisU.z + bezpatch[15].pos * basisU.w);

	return value;
}

[domain("quad")]
DomainToPixel main(PatchConstantData input, float2 domain : SV_DomainLocation, const OutputPatch<HullToDomain, NUM_CONTROL_POINTS> patch, uint patchID : SV_PrimitiveID)
{
	// Evaluate the basis functions at (u, v)
	float4 basisU = BernsteinBasis(domain.x);
	float4 basisV = BernsteinBasis(domain.y);

	// Evaluate the surface position for this vertex
	float3 localPos = evaluateBezier(patch, basisU, basisV);

	float4x4 transform = patchTransforms[patchID].transform;
	float4 localPosTransformed = mul(float4(localPos, 1.0f), transform);

	DomainToPixel output;
	output.pos = mul(localPosTransformed, constPerObject.wvpMat);
	output.color = patchColors[patchID].color;

	return output;
}
----

Going from top we see that we're operating on the same `16` point patch, we have a constant buffer for the teapot`s world-view-projection transform, structured buffer for the patch transform and structured buffer for the patch color. On practice we can use one structured buffer for both transforms and colors but I deliberately split it in two to show how we can assign resources through the root table (more on this later). This data we're receiving from the application.

NOTE: There're some places where I chose non optimal path and did this by purpose - maybe for simplicity or maybe to show different possibilities of the api. In such places I added a note. But if you found a place where things done poorly and there's no note around - that means I simply missed something and it would be great if you point this in the comment so I can make a fix.

There're also structs: `PatchConstantData` and `HullToDomain` - data from the `hull` shader (remember that position is a pass through from the `vertex` shader which also passes it through from the input assembler), `DomainToPixel` - the data we're passing further the pipeline - to the `pixel` shader.

Next is a pure math - in the `main()` function we have a list of control points for one patch (`16` points) and we need to sample them so we can assign a position to the new vertex generated by tesselator. The good overview of the math behind you can find http://www.gamasutra.com/view/feature/131755/curved_surfaces_using_bzier_.php[here]. Also http://www.gdcvault.com/play/1012740/direct3d[this presentation] is a very good reading about patch tesselation in `directx 11` (I took the most shader code from there to be honest).

So what are we doing in the `main()` function? The first `3` function parameters are pretty standard - the constant data which we defined in the `hull` shader (not used here, but have to be provided), `uv` coordinates for our point in the square (quad) domain - generated by tesselator, and initial patch information from the hull shader. The last parameter - `PatchID` with special semantics is worth paying attention. As you remember, in our demo we have the total number of patches equal to `28`. And we want to apply some parameters to the entire patch, for example a color. That means that for every generated vertex in the same patch we need to assign the same color information and pass it to the `pixel` shader. And this is where `SV_PrimitiveID` semantics will come to the rescue - for every vertex of the same patch (no matter how many vertices were generated) this value will be the same. The first patch will get id of `0`, second patch - `1` and so on. One thing worth to remember - all patches should be rendered in one draw call. Every new draw call resets the id (as well as new instance in instance drawing).

First we're finding the vertex position in patch space. Next with the help of the patch id we're obtaining patch transform (remember an example - we need rotate a rim `4` times) and applying it to the vertex. Next we're transforming the vertex to the homogenious space by multiplying it on world-view-projection matrix. In the final step we're sampling the color structured buffer and sending this data to our last programmable stage - `pixel` shader.

This function will be called for every generated vertex (generated by tesselator). The number of generated vertices depends on the tesselation factors (edge and inside for the quad patch) and partitioning scheme (`[partitioning("integer")]` in the `hull` shader).

*Pixel shader*

This is also very simple shader, don't even need to be discussed. You can find the code https://github.com/nikitablack/directx-12/blob/master/TeapotTutorial/TeapotTutorial/PixelShader.hlsl[here].

That's basically it - we have a program and we need to make our hardware run it. All other code just exist for this purpose - to help the gpu execute shaders. To summarize things I drew a diagram that shows shader stages and resources we need.

image::teapot_tutorial/shader_res_1.png[Shader Resources, 800, link="https://raw.githubusercontent.com/nikitablack/nikitablack.github.io/master/images/teapot_tutorial/shader_res_1.png"]

Couple of things to note. Resources stored in gpu in memory. Gpu have no idea what's stored inside its memory and how to interpret it - it's just a blob of data. It's our task to tell it where the data resides, the size and format. For `vertex buffer` and `index buffer` it's pretty easy - we create this buffers and later tell the gpu to use it with `ID3D12GraphicsCommandList::IASetVertexBuffers()` and `ID3D12GraphicsCommandList::IASetIndexBuffer()` methods. On the diagram I showed solid arrow from input to this resources. With other resources things are different. There's no such method like `DSSetStructuredBufferInSlot()` or similar and we need to use special structure called `RootSignature` to bind shaders and resources together. That's why there're question marks between shader and resource. We'll find out how to bind resources in the next sections. Also on the diagram I specified the size of our data together with alignment size (for example `1416B / 64kB` for the `vertex buffer`). Id `directx 12` (and `11`) buffers should be aligned by `64kB`. We can specify this value during resource creation or let the api do it for us. That means if we have a lot of small buffers we're wasting a lot of space. But it's just an interesting point and we shoudn't bother about it in this example.

===== Briefly about Descriptors

As I mentioned above gpu can't use resource memory directly. How can we say then that part of memory is a structured buffer, for example? As you already guessed - with a *descriptor* (another name is *view*). This is a small structure that describes the resource - it's format, size etc. Since this information used by gpu it's convenient to strore it in the gpu itself. We can't store descriptor directly in memory but can in special place called descriptor heap. We'll touch descriptors more closely in later sections but for now you just need to remember that resource is stored in memory is just a bunch on bits and bytes. This bunch can be described with descriptors - lightweight data that tells gpu how to interpret particular part of memory. This descriptors are stored in gpu memory in descriptor heaps. Of course `directx` wouldn't be `directx` if everything would be so easy - there different ways to provide information to the gpu, for example we can bypass descriptor heap and pass descriptor directly. We'll cover this options in the course of this article.

===== Code Organization

When I started to write this tutorial I wanted to make it as simple as possible and put everything in one file. But when this file became more than `1000` lines I decided to split the code on several logic units. `Window` is a class which encapsulates window creation and accepts a key press callback in the form of `std::function`. We'll use this callback to change demo parameters. 'Graphics` is a base class for our demo. It creates a 'Window' and also initializes `d3d`, i.e. it creates interfaces that are used by all graphics` applications. For example device, swap chain, depth buffer, back buffers, command list and so on. `TeapotTutorial` extends this class and adds functionality related to our demo - resources creation, rendering. I'll describe why each method exist ans we'll start with `TeapotTutorial::createRootSignature()`.

===== Root Signature

Ok, at this point we should know that shaders require resources and this resources should be bound to the correct resource slots (`b0` for constant buffer, `t0` for structured buffer, for eample). In `directx 12` we do it it with special interface - `ID3D12RootSignature`. With it we need to describe which resources which shader needs and which slot. We can say that it only describes input parameters, just like usual c++ function signature. For example:

[source,cpp]
----
void rootSignature(std::array<int, 2> constants, XMFLOAT4X4* wvpMatrix, std::vector<XMFLOAT3*>* colors);
----

What we see here is that our function expects `3` input parameters - two ints, copied by value; pointer to a matrix, and a pointer to vector of pointers to some colors. If we're going to read these passed values we'll have this: the first parameter - two ints / will be copied to registers so accessing them will be extremely fast; for the second parameter we need to dereference a pointer and it will lead to read from memory with potential cache miss, so it's slower that the first parameter; the fird parameter is the slowest one - to read from the vector we need to dereference it first and then dereference the element we want to access - that means two indirections. Also notice that this is just a signature - it doesn't tell us what are the actual parameter values. Basically we can use as many different combinations of parameters as we can imagine with a single signature - the only mandatory is that we need to maintain correct types. Why did I tell all this? Because this is exactly how root signature works! We specify the input parameters and there types and later during runtime we pass the actual data.

We're almost ready to start write a code but let's first discuss our input signature. As you remember we have `4` resources for our demo - `hull` constant buffer, `domain` constant buffer and `2` `domain` structured buffers.

NOTE: "But there're also `vertex` and `index` buffers" - can ask somebody. Right, but they are _special_ buffers - we need to create a resources and corresponding views and this views we pass directly to pipeline in command list (as we'll see later). These views don't even need a resource heap!

Also as we saw previously, the information about this resources should be stored in descriptors which should be stored in descriptor heaps. But I also mentioned that there're some other ways to pass data around. That's how we'll do it:

1. Tesselation factors for the `hull` shader we'll pass *directly* in root signature. That means we don't need to create descriptor or descriptor heap or even resource itself! This works because we can pass `32` bit constants in root signature and they appear in shader as a constant buffer. Since we have only `2` tesselation factors this type of passing looks like a good choice. Moreover, this data will be accessed in a shader without indirection, just like `std::array<int, 2>` in an example c++ function signature!

2. For `domain` shader's constant buffer we will use a descriptor. But this decriptor will be passed as a part of the root signature. And that means we can bypass a descriptor heap. The descriptor will be inlined in the root signature - that's why we don't need to store it somewhere else. With descriptor, in order to acces the resource the shader will need first it's address in descriptor and than read the actual data. Just like `XMFLOAT4X4*` in an example c++ function signature!

3. For `domain` shader's structured buffers we will finaly use descriptor and descriptor heaps. That means we need to create a descriptor heap to hold `2` descriptors (one for every buffer) and desciptors itself. In order to pass information to the root signature we need to pack it to descriptor table. Descriptor table just tells which descriptor heap to use and the number of descriptors. When we need to access a buffer in a shader the runtime will first read the table, next will read the descriptor and finally will read the actual data. Just like `std::vector<XMFLOAT3*>*` in an example c++ function signature!

A question: why do we need to use descriptors or tables if we can pass everything as root constants?
The answer: root signature have a very limited size - `64DWORD` (`1DWORD` = `32bit`). That means we can store `64` ints inside it, or `4` matrices. If there's not enough place the data will be stored somewhere else and it will add one more level of indirection. Root descriptor asks for `2DWORD` and table only `1DWORD`.

NOTE: Interesting note - https://developer.nvidia.com/dx12-dos-and-donts#roots[Nvidia] guys recommend to use root descriptors as much as you can. But http://gpuopen.com/performance-root-signature-descriptor-sets/[AMD] guys recommend to use tables.

Remember that signature doesn't define any parameters - it just declares the type and the order. The actual data will be passed later.

Knowing all this we can write our first `directx 12` code.

[source,cpp]
----
// TeapotTutorial.h
Microsoft::WRL::ComPtr<ID3D12RootSignature> rootSignature;

// TeapotTutorial.cpp
void TeapotTutorial::createRootSignature()
{
	/* We're using 3 root parameters:
	- root descriptor for domain shader's constant buffer
	- 2 root constants for hull shader's constant buffer
	- descriptor table for 2 structured buffers
	*/

	// this is the range of decriptors in the descriptor heap
	D3D12_DESCRIPTOR_RANGE dsTransformAndColorSrvRange;
	ZeroMemory(&dsTransformAndColorSrvRange, sizeof(dsTransformAndColorSrvRange));
	dsTransformAndColorSrvRange.RangeType = D3D12_DESCRIPTOR_RANGE_TYPE_SRV; // we're using structured buffers - it's a SRV
	dsTransformAndColorSrvRange.NumDescriptors = 2; // we have 2 structured buffers and 2 descriptors
	dsTransformAndColorSrvRange.BaseShaderRegister = 0; // we start from the first register (t0)
	dsTransformAndColorSrvRange.RegisterSpace = 0; // this allows us to use the same register name if we use different space
	dsTransformAndColorSrvRange.OffsetInDescriptorsFromTableStart = D3D12_DESCRIPTOR_RANGE_OFFSET_APPEND;

	// root table parameter
	D3D12_ROOT_PARAMETER dsTransformAndColorSrv;
	ZeroMemory(&dsTransformAndColorSrv, sizeof(dsTransformAndColorSrv));
	dsTransformAndColorSrv.ParameterType = D3D12_ROOT_PARAMETER_TYPE_DESCRIPTOR_TABLE;
	dsTransformAndColorSrv.DescriptorTable = { 1, &dsTransformAndColorSrvRange }; // one range
	dsTransformAndColorSrv.ShaderVisibility = D3D12_SHADER_VISIBILITY_DOMAIN; // only used in domain shader

	// root descriptor parameter
	D3D12_ROOT_PARAMETER dsObjCb;
	ZeroMemory(&dsObjCb, sizeof(dsObjCb));
	dsObjCb.ParameterType = D3D12_ROOT_PARAMETER_TYPE_CBV; // constant buffer
	dsObjCb.Descriptor = { 0, 0 }; // first register (b0) in first register space
	dsObjCb.ShaderVisibility = D3D12_SHADER_VISIBILITY_DOMAIN; // only used in domain shader

	// root constants
	D3D12_ROOT_PARAMETER hsTessFactorsCb;
	ZeroMemory(&hsTessFactorsCb, sizeof(hsTessFactorsCb));
	hsTessFactorsCb.ParameterType = D3D12_ROOT_PARAMETER_TYPE_32BIT_CONSTANTS;
	hsTessFactorsCb.Constants = { 0, 0, 2 }; // 2 constants in first register (b0) in first register space
	hsTessFactorsCb.ShaderVisibility = D3D12_SHADER_VISIBILITY_HULL; // only used in hull shader

	vector<D3D12_ROOT_PARAMETER> rootParameters{ dsObjCb, hsTessFactorsCb, dsTransformAndColorSrv };
	
	// it's recommended to deny root signature access to the stages that are not interested in it
	D3D12_ROOT_SIGNATURE_FLAGS rootSignatureFlags{
		D3D12_ROOT_SIGNATURE_FLAG_ALLOW_INPUT_ASSEMBLER_INPUT_LAYOUT | // we're using vertex and index buffers
		D3D12_ROOT_SIGNATURE_FLAG_DENY_VERTEX_SHADER_ROOT_ACCESS |
		D3D12_ROOT_SIGNATURE_FLAG_DENY_GEOMETRY_SHADER_ROOT_ACCESS |
		D3D12_ROOT_SIGNATURE_FLAG_DENY_PIXEL_SHADER_ROOT_ACCESS
	};

	D3D12_ROOT_SIGNATURE_DESC rootSignatureDesc;
	ZeroMemory(&rootSignatureDesc, sizeof(rootSignatureDesc));
	rootSignatureDesc.NumParameters = static_cast<UINT>(rootParameters.size());
	rootSignatureDesc.pParameters = rootParameters.data();
	rootSignatureDesc.NumStaticSamplers = 0; // samplers can be stored in root signature separately and consume no space
	rootSignatureDesc.pStaticSamplers = nullptr; // we're not using texturing
	rootSignatureDesc.Flags = rootSignatureFlags;

	// we need to serialize first. This is useful because root siganture can be defined directly in a shader, not c++ app
	ComPtr<ID3DBlob> signature;
	ComPtr<ID3DBlob> error;
	if (FAILED(D3D12SerializeRootSignature(&rootSignatureDesc, D3D_ROOT_SIGNATURE_VERSION_1, signature.ReleaseAndGetAddressOf(), error.ReleaseAndGetAddressOf())))
	{
		throw(runtime_error{ "Error serializing root signature" });
	}

	// finally create the root signature
	if (FAILED(device->CreateRootSignature(0, signature->GetBufferPointer(), signature->GetBufferSize(), IID_PPV_ARGS(rootSignature.ReleaseAndGetAddressOf()))))
	{
		throw(runtime_error{ "Error creating root signature" });
	}
}
----

NOTE: `Directx` team kindly provided a helper header that simplifies creation of different structures - `d3dx12.h`. Thought the header is not a part of `directx 12` it's https://msdn.microsoft.com/en-us/library/windows/desktop/dn708058(v=vs.85).aspx[well documented] in `msdn` and pretty solid. The `D3D12_DESCRIPTOR_RANGE` creation can be replaced with `CD3DX12_DESCRIPTOR_RANGE`, `D3D12_ROOT_PARAMETER` with `CD3DX12_ROOT_PARAMETER` and `D3D12_ROOT_SIGNATURE_DESC` with `CD3DX12_ROOT_SIGNATURE_DESC`. Using this helpers allow us to reduce and hence simplify code dramatically. I deliberatelly removed all `d3dx12.h` dependencies from my code just to show how `directx` works under the hood.

When you serializing the signature you can get errors which will be writtent to `error` instance. There're a lot of checks happens during serialization - for example if you overlap registers for the same shader (have two 'b0') you'll get an error. Very handy tool!

Now when we know about root signature we can update our diagram:

image::teapot_tutorial/shader_res_1.png[Shader Resources, 800, link="https://raw.githubusercontent.com/nikitablack/nikitablack.github.io/master/images/teapot_tutorial/shader_res_2.png"]

The last method - `device->CreateRootSignature()` uses some `device` that we don't know yet. This is a software representation of the hardware - `ID3D12Device`. During `directx` evolution the api gets expanded and new interfaces appears that extend old and adds new functionality. At the moment of writing there's `ID3D12Device1` available. I really like the naming! Now it's time to initialize `directx`.

===== DirectX Initialization

As I told before base initialization is done in the base class called `Graphics`. This is how we create a device:

[source,cpp]
----
// Graphics.h
Microsoft::WRL::ComPtr<ID3D12Device> device;

// Graphics.cpp
void Graphics::createDevice()
{
	if (FAILED(D3D12CreateDevice(adapter.Get(), D3D_FEATURE_LEVEL_11_0, IID_PPV_ARGS(&device))))
	{
		throw(runtime_error{ "Error creating device." });
	}
}
----

Simple enough. But what is this `adapter`. We can use `nullptr` instead and let the api to choose the default adapter, but I'll show here how we can select among many adapters. Similar to `device` it's an `IDXGIAdapter` interface that represents a gpu. It's hard for me to tell why do we need two similar interfaces that represents basically the same thing. Let's think that `dxgi` interface provides different information about gpu, but `d3d` interface allows us to manipulate it - create different resources, change states. We'll use `IDXGIAdapter3` interface:

[source,cpp]
----
// Graphics.h
Microsoft::WRL::ComPtr<IDXGIAdapter3> adapter;

// Graphics.cpp
void Graphics::getAdapter()
{
	ComPtr<IDXGIAdapter1> adapterTemp;

	for (UINT adapterIndex{ 0 }; factory->EnumAdapters1(adapterIndex, adapterTemp.ReleaseAndGetAddressOf()) != DXGI_ERROR_NOT_FOUND; ++adapterIndex)
	{
		DXGI_ADAPTER_DESC1 desc;
		ZeroMemory(&desc, sizeof(desc));

		adapterTemp->GetDesc1(&desc);

		if (desc.Flags & DXGI_ADAPTER_FLAG_SOFTWARE)
		{
			continue;
		}

		if (SUCCEEDED(adapterTemp.As(&adapter)))
		{
			break;
		}
	}

	if (adapter == nullptr)
	{
		throw(runtime_error{ "Error getting an adapter." });
	}
}
----

If you thought we're finished you were strongly mistaken. We're taking the first adapter that is not software (starting from `Windows 8` there's always a software adapter presented in the system). But you can use different logic - like checking the vendor. For enumerating we're using some `factory` which is `IDXGIFactory4` interface. So let's grab it:

[source,cpp]
----
// Graphics.h
Microsoft::WRL::ComPtr<IDXGIFactory4> factory;

// Graphics.cpp
void Graphics::createFactory()
{
#if defined(_DEBUG) 
	ComPtr<ID3D12Debug> debugController;
	if (SUCCEEDED(D3D12GetDebugInterface(IID_PPV_ARGS(&debugController))))
	{
		debugController->EnableDebugLayer();
	}
#endif

	UINT factoryFlags{ 0 };
#if _DEBUG
	factoryFlags = DXGI_CREATE_FACTORY_DEBUG;
#endif

	if (FAILED(CreateDXGIFactory2(factoryFlags, IID_PPV_ARGS(factory.ReleaseAndGetAddressOf()))))
	{
		throw(runtime_error{ "Error creating IDXGIFactory." });
	}
}
----

Finally no more new dependent interfaces! Thought there's one which we not depend on - `ID3D12Debug`. You should always use it with debug configuration. During an error it writes detailed message to the output. Now you can compile it successfully thought you'll not see anything on the screen. That's one of the downside of programming with `directx` - you can't have some intermediate results like render only one triangle from the teapot or shade only one pixel. You need to write a lot of code for both cpu and gpu to find the black screen. Nevertheless we'll continue. At yhis point we have defined shaders and a signature for the input. But the gpu doesn't know about our shaders - we only have several text files that are useful for us - not the hardware. As you have guessed we need to load out shaders to the graphics card. First we need to compile them. Later we'll use a new addtition to the api which allows us to send this data (and a lot of other) to the gpu - pipeline state object.

===== Pipeline State Object

As you know the gpu is a state machine - once it's setted up it will do the same actions again and again. Until you change a state. In `directx 12` the entire gpu state (plus or minus some minor things) is represented by `ID3D12PipelineState` interface. That mean that if you want to render the same object in wireframe and solid you have to create `2` such objects which will differ only by fill mode. State creation is a heavy operation that should be avoided in runtime. Instead all states that you need for your scene should be created as a part of initialization.

In our demo we'll use `2` states - one for solid rendering and backface culling and another for wireframe rendering and without culling. Creating a state means filling a lot of structures and setting shaders. We're compiling our shaders as a build process in Visual Studio. Taht means that at this point you should have `cso` files somewhere which we need to load. The loading done like this:

[source,cpp]
----
// TeapotTutorial.h
Microsoft::WRL::ComPtr<ID3DBlob> vertexShaderBlob;
Microsoft::WRL::ComPtr<ID3DBlob> hullShaderBlob;
Microsoft::WRL::ComPtr<ID3DBlob> domainShaderBlob;
Microsoft::WRL::ComPtr<ID3DBlob> pixelShaderBlob;

// TeapotTutorial.cpp
void TeapotTutorial::createShaders()
{
	if (FAILED(D3DReadFileToBlob(L"VertexShader.cso", vertexShaderBlob.ReleaseAndGetAddressOf())))
	{
		throw(runtime_error{ "Error reading vertex shader." });
	}

	if (FAILED(D3DReadFileToBlob(L"HullShader.cso", hullShaderBlob.ReleaseAndGetAddressOf())))
	{
		throw(runtime_error{ "Error reading hull shader." });
	}

	if (FAILED(D3DReadFileToBlob(L"DomainShader.cso", domainShaderBlob.ReleaseAndGetAddressOf())))
	{
		throw(runtime_error{ "Error reading domain shader." });
	}

	if (FAILED(D3DReadFileToBlob(L"PixelShader.cso", pixelShaderBlob.ReleaseAndGetAddressOf())))
	{
		throw(runtime_error{ "Error reading pixel shader." });
	}
}
----

And the pipeline state creation (remember - we have `2` states):

[source,cpp]
----
// TeapotTutorial.h
Microsoft::WRL::ComPtr<ID3D12PipelineState> pipelineStateWireframe;
Microsoft::WRL::ComPtr<ID3D12PipelineState> pipelineStateSolid;
Microsoft::WRL::ComPtr<ID3D12PipelineState> currPipelineState;

// TeapotTutorial.cpp
void TeapotTutorial::createPipelineStateWireframe()
{
	pipelineStateWireframe = createPipelineState(D3D12_FILL_MODE_WIREFRAME, D3D12_CULL_MODE_NONE);
	currPipelineState = pipelineStateWireframe;
}

void TeapotTutorial::createPipelineStateSolid()
{
	pipelineStateSolid = createPipelineState(D3D12_FILL_MODE_SOLID, D3D12_CULL_MODE_NONE);
}

ComPtr<ID3D12PipelineState> TeapotTutorial::createPipelineState(D3D12_FILL_MODE fillMode, D3D12_CULL_MODE cullMode)
{
	vector<D3D12_INPUT_ELEMENT_DESC> inputElementDescs
	{
		{ "POSITION", 0, DXGI_FORMAT_R32G32B32_FLOAT, 0, 0, D3D12_INPUT_CLASSIFICATION_PER_VERTEX_DATA, 0 }
	};

	D3D12_RASTERIZER_DESC rasterizerDesc;
	ZeroMemory(&rasterizerDesc, sizeof(rasterizerDesc));
	rasterizerDesc.FillMode = fillMode;
	rasterizerDesc.CullMode = cullMode;
	rasterizerDesc.FrontCounterClockwise = FALSE;
	rasterizerDesc.DepthBias = D3D12_DEFAULT_DEPTH_BIAS;
	rasterizerDesc.DepthBiasClamp = D3D12_DEFAULT_DEPTH_BIAS_CLAMP;
	rasterizerDesc.SlopeScaledDepthBias = D3D12_DEFAULT_SLOPE_SCALED_DEPTH_BIAS;
	rasterizerDesc.DepthClipEnable = TRUE;
	rasterizerDesc.MultisampleEnable = FALSE;
	rasterizerDesc.AntialiasedLineEnable = FALSE;
	rasterizerDesc.ForcedSampleCount = 0;
	rasterizerDesc.ConservativeRaster = D3D12_CONSERVATIVE_RASTERIZATION_MODE_OFF;

	D3D12_BLEND_DESC blendDesc;
	ZeroMemory(&blendDesc, sizeof(blendDesc));
	blendDesc.AlphaToCoverageEnable = FALSE;
	blendDesc.IndependentBlendEnable = FALSE;
	blendDesc.RenderTarget[0] = {
		FALSE,FALSE,
		D3D12_BLEND_ONE, D3D12_BLEND_ZERO, D3D12_BLEND_OP_ADD,
		D3D12_BLEND_ONE, D3D12_BLEND_ZERO, D3D12_BLEND_OP_ADD,
		D3D12_LOGIC_OP_NOOP,
		D3D12_COLOR_WRITE_ENABLE_ALL
	};

	D3D12_DEPTH_STENCIL_DESC depthStencilDesc;
	ZeroMemory(&depthStencilDesc, sizeof(depthStencilDesc));
	depthStencilDesc.DepthEnable = TRUE;
	depthStencilDesc.DepthWriteMask = D3D12_DEPTH_WRITE_MASK_ALL;
	depthStencilDesc.DepthFunc = D3D12_COMPARISON_FUNC_LESS;
	depthStencilDesc.StencilEnable = FALSE;
	depthStencilDesc.StencilReadMask = D3D12_DEFAULT_STENCIL_READ_MASK;
	depthStencilDesc.StencilWriteMask = D3D12_DEFAULT_STENCIL_WRITE_MASK;
	const D3D12_DEPTH_STENCILOP_DESC defaultStencilOp = { D3D12_STENCIL_OP_KEEP, D3D12_STENCIL_OP_KEEP, D3D12_STENCIL_OP_KEEP, D3D12_COMPARISON_FUNC_ALWAYS };
	depthStencilDesc.FrontFace = defaultStencilOp;
	depthStencilDesc.BackFace = defaultStencilOp;

	D3D12_GRAPHICS_PIPELINE_STATE_DESC pipelineStateDesc;
	ZeroMemory(&pipelineStateDesc, sizeof(pipelineStateDesc));
	pipelineStateDesc.InputLayout = { inputElementDescs.data(), static_cast<UINT>(inputElementDescs.size()) };
	pipelineStateDesc.pRootSignature = rootSignature.Get();
	pipelineStateDesc.VS = { vertexShaderBlob->GetBufferPointer(), vertexShaderBlob->GetBufferSize() };
	pipelineStateDesc.HS = { hullShaderBlob->GetBufferPointer(), hullShaderBlob->GetBufferSize() };
	pipelineStateDesc.DS = { domainShaderBlob->GetBufferPointer(), domainShaderBlob->GetBufferSize() };
	pipelineStateDesc.PS = { pixelShaderBlob->GetBufferPointer(), pixelShaderBlob->GetBufferSize() };
	pipelineStateDesc.RasterizerState = rasterizerDesc;
	pipelineStateDesc.BlendState = blendDesc;
	pipelineStateDesc.DepthStencilState = depthStencilDesc;
	pipelineStateDesc.SampleMask = UINT_MAX;
	pipelineStateDesc.PrimitiveTopologyType = D3D12_PRIMITIVE_TOPOLOGY_TYPE_PATCH;
	pipelineStateDesc.NumRenderTargets = 1;
	pipelineStateDesc.RTVFormats[0] = DXGI_FORMAT_R8G8B8A8_UNORM;
	pipelineStateDesc.DSVFormat = DXGI_FORMAT_D32_FLOAT;
	pipelineStateDesc.SampleDesc.Count = 1;

	ComPtr<ID3D12PipelineState> pipelineState;
	if (FAILED(device->CreateGraphicsPipelineState(&pipelineStateDesc, IID_PPV_ARGS(pipelineState.ReleaseAndGetAddressOf()))))
	{
		throw(runtime_error{ "Error creating pipeline state." });
	}

	return pipelineState;
}
----

Wow, that's a lot of code. Let's step through the code line by line. First we create input layout. In `vertex` shader we're expecting only one input - the control point position so we have only one entry in `D3D12_INPUT_ELEMENT_DESC` vector. Next we create a rasterizer state. This structure can be replaced with a helper `CD3DX12_RASTERIZER_DESC` to make it shorter. Next is blend (can be replaced with `CD3DX12_BLEND_DESC`). Next is depth stencil (`CD3DX12_DEPTH_STENCIL_DESC`). And finally pipeline state object itself where we assign all the things we created. I think it should be clear from the names what each field represents so I won't describe it in detail.

NOTE: Interesting thing - thought we assigned a root signature to pipeline state this assignmend done only for validation, i.e. the api will check that shader inputs correspond to signature parameters. After pipeline state creation the information about root signature is lost and we need to assign it again before drawing.